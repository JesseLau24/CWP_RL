{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merging completed. Merged file saved as '/home/jesse/Projects/CWP_RL/03_XGBoost_Return_Prediction/SP500_15_22/15_22_merged_stocks.csv'.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Stock_ID</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-01-02</td>\n",
       "      <td>A</td>\n",
       "      <td>37.923997</td>\n",
       "      <td>38.043719</td>\n",
       "      <td>37.178040</td>\n",
       "      <td>37.353020</td>\n",
       "      <td>1529200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-01-02</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>24.778673</td>\n",
       "      <td>24.789796</td>\n",
       "      <td>23.879976</td>\n",
       "      <td>24.320427</td>\n",
       "      <td>212818400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-01-02</td>\n",
       "      <td>ABBV</td>\n",
       "      <td>42.861468</td>\n",
       "      <td>43.490242</td>\n",
       "      <td>42.861468</td>\n",
       "      <td>43.156204</td>\n",
       "      <td>5086100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-01-02</td>\n",
       "      <td>ABT</td>\n",
       "      <td>37.202783</td>\n",
       "      <td>37.367216</td>\n",
       "      <td>36.701264</td>\n",
       "      <td>36.915028</td>\n",
       "      <td>3216600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-01-02</td>\n",
       "      <td>ACGL</td>\n",
       "      <td>18.764398</td>\n",
       "      <td>18.884845</td>\n",
       "      <td>18.472788</td>\n",
       "      <td>18.539352</td>\n",
       "      <td>1101600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2015-01-02</td>\n",
       "      <td>ACN</td>\n",
       "      <td>76.016365</td>\n",
       "      <td>76.372412</td>\n",
       "      <td>74.965176</td>\n",
       "      <td>75.312744</td>\n",
       "      <td>2021300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2015-01-02</td>\n",
       "      <td>ADBE</td>\n",
       "      <td>72.699997</td>\n",
       "      <td>73.199997</td>\n",
       "      <td>71.889999</td>\n",
       "      <td>72.339996</td>\n",
       "      <td>2349200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2015-01-02</td>\n",
       "      <td>ADI</td>\n",
       "      <td>45.003796</td>\n",
       "      <td>45.464503</td>\n",
       "      <td>44.429934</td>\n",
       "      <td>44.890640</td>\n",
       "      <td>1323200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2015-01-02</td>\n",
       "      <td>ADM</td>\n",
       "      <td>38.834026</td>\n",
       "      <td>39.131603</td>\n",
       "      <td>38.380218</td>\n",
       "      <td>38.700115</td>\n",
       "      <td>2039800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2015-01-02</td>\n",
       "      <td>ADP</td>\n",
       "      <td>66.412449</td>\n",
       "      <td>67.372858</td>\n",
       "      <td>66.044286</td>\n",
       "      <td>66.660553</td>\n",
       "      <td>1866600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Date Stock_ID       Open       High        Low      Close     Volume\n",
       "0 2015-01-02        A  37.923997  38.043719  37.178040  37.353020    1529200\n",
       "1 2015-01-02     AAPL  24.778673  24.789796  23.879976  24.320427  212818400\n",
       "2 2015-01-02     ABBV  42.861468  43.490242  42.861468  43.156204    5086100\n",
       "3 2015-01-02      ABT  37.202783  37.367216  36.701264  36.915028    3216600\n",
       "4 2015-01-02     ACGL  18.764398  18.884845  18.472788  18.539352    1101600\n",
       "5 2015-01-02      ACN  76.016365  76.372412  74.965176  75.312744    2021300\n",
       "6 2015-01-02     ADBE  72.699997  73.199997  71.889999  72.339996    2349200\n",
       "7 2015-01-02      ADI  45.003796  45.464503  44.429934  44.890640    1323200\n",
       "8 2015-01-02      ADM  38.834026  39.131603  38.380218  38.700115    2039800\n",
       "9 2015-01-02      ADP  66.412449  67.372858  66.044286  66.660553    1866600"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Directory containing CSV files\n",
    "directory = \"/home/jesse/Projects/CWP_RL/03_XGBoost_Return_Prediction/SP500_15_22\"\n",
    "\n",
    "# Get a list of all CSV files\n",
    "csv_files = [f for f in os.listdir(directory) if f.endswith(\".csv\")]\n",
    "\n",
    "# Initialize an empty list to store individual stock DataFrames\n",
    "dfs = []\n",
    "\n",
    "# Read and store each CSV file\n",
    "for file in csv_files:\n",
    "    stock_df = pd.read_csv(os.path.join(directory, file), parse_dates=[\"Date\"])\n",
    "    stock_df[\"Stock_ID\"] = file.replace(\".csv\", \"\")  # Add stock ticker as an identifier\n",
    "    dfs.append(stock_df)\n",
    "\n",
    "# Concatenate all stock DataFrames\n",
    "training_df = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "# Sort by Date first, then by Stock_ID\n",
    "training_df = training_df.sort_values(by=[\"Date\", \"Stock_ID\"]).reset_index(drop=True)\n",
    "\n",
    "# Reorder columns: Date → Stock_ID → Other Columns\n",
    "cols = [\"Date\", \"Stock_ID\"] + [col for col in training_df.columns if col not in [\"Date\", \"Stock_ID\"]]\n",
    "training_df = training_df[cols]\n",
    "\n",
    "# Save merged data to a new CSV file\n",
    "training_csv_path = os.path.join(directory, \"15_22_merged_stocks.csv\")\n",
    "training_df.to_csv(training_csv_path, index=False)\n",
    "\n",
    "print(f\"Merging completed. Merged file saved as '{training_csv_path}'.\")\n",
    "\n",
    "training_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature engineering complete. Saved to /home/jesse/Projects/CWP_RL/03_XGBoost_Return_Prediction/SP500_15_22/15_22_merged_stocks_features.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Stock_ID</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Return_1d</th>\n",
       "      <th>Return_5d</th>\n",
       "      <th>Return_10d</th>\n",
       "      <th>Return_50d</th>\n",
       "      <th>Volatility_5d</th>\n",
       "      <th>Volatility_10d</th>\n",
       "      <th>Volatility_20d</th>\n",
       "      <th>SMA_10</th>\n",
       "      <th>SMA_50</th>\n",
       "      <th>SMA_200</th>\n",
       "      <th>RSI_14</th>\n",
       "      <th>Volume_Change_5d</th>\n",
       "      <th>Volume_Change_10d</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-01-02</td>\n",
       "      <td>A</td>\n",
       "      <td>37.923997</td>\n",
       "      <td>38.043719</td>\n",
       "      <td>37.178040</td>\n",
       "      <td>37.353020</td>\n",
       "      <td>1529200</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-01-05</td>\n",
       "      <td>A</td>\n",
       "      <td>37.131988</td>\n",
       "      <td>37.260918</td>\n",
       "      <td>36.561011</td>\n",
       "      <td>36.653103</td>\n",
       "      <td>2041800</td>\n",
       "      <td>-0.018738</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-01-06</td>\n",
       "      <td>A</td>\n",
       "      <td>36.662315</td>\n",
       "      <td>36.855710</td>\n",
       "      <td>35.934778</td>\n",
       "      <td>36.082127</td>\n",
       "      <td>2080600</td>\n",
       "      <td>-0.015578</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-01-07</td>\n",
       "      <td>A</td>\n",
       "      <td>36.395256</td>\n",
       "      <td>36.662327</td>\n",
       "      <td>36.183441</td>\n",
       "      <td>36.561024</td>\n",
       "      <td>3359700</td>\n",
       "      <td>0.013272</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-01-08</td>\n",
       "      <td>A</td>\n",
       "      <td>37.058314</td>\n",
       "      <td>37.739802</td>\n",
       "      <td>37.003057</td>\n",
       "      <td>37.656918</td>\n",
       "      <td>2116300</td>\n",
       "      <td>0.029974</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2015-01-09</td>\n",
       "      <td>A</td>\n",
       "      <td>37.758228</td>\n",
       "      <td>37.758228</td>\n",
       "      <td>37.104367</td>\n",
       "      <td>37.380646</td>\n",
       "      <td>1644900</td>\n",
       "      <td>-0.007337</td>\n",
       "      <td>0.000740</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.020747</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.075660</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2015-01-12</td>\n",
       "      <td>A</td>\n",
       "      <td>37.399065</td>\n",
       "      <td>37.500368</td>\n",
       "      <td>36.791250</td>\n",
       "      <td>36.938599</td>\n",
       "      <td>2770800</td>\n",
       "      <td>-0.011826</td>\n",
       "      <td>0.007789</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.019342</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.357038</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2015-01-13</td>\n",
       "      <td>A</td>\n",
       "      <td>37.270130</td>\n",
       "      <td>37.481944</td>\n",
       "      <td>36.220268</td>\n",
       "      <td>36.422871</td>\n",
       "      <td>2013100</td>\n",
       "      <td>-0.013962</td>\n",
       "      <td>0.009444</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.018992</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.032443</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2015-01-14</td>\n",
       "      <td>A</td>\n",
       "      <td>35.943981</td>\n",
       "      <td>36.008446</td>\n",
       "      <td>35.188817</td>\n",
       "      <td>35.971611</td>\n",
       "      <td>5134000</td>\n",
       "      <td>-0.012389</td>\n",
       "      <td>-0.016121</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.018657</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.528113</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2015-01-15</td>\n",
       "      <td>A</td>\n",
       "      <td>36.220261</td>\n",
       "      <td>36.293934</td>\n",
       "      <td>34.986212</td>\n",
       "      <td>35.004627</td>\n",
       "      <td>2628900</td>\n",
       "      <td>-0.026882</td>\n",
       "      <td>-0.070433</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.007357</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>36.602454</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.242215</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Date Stock_ID       Open       High        Low      Close   Volume  \\\n",
       "0 2015-01-02        A  37.923997  38.043719  37.178040  37.353020  1529200   \n",
       "1 2015-01-05        A  37.131988  37.260918  36.561011  36.653103  2041800   \n",
       "2 2015-01-06        A  36.662315  36.855710  35.934778  36.082127  2080600   \n",
       "3 2015-01-07        A  36.395256  36.662327  36.183441  36.561024  3359700   \n",
       "4 2015-01-08        A  37.058314  37.739802  37.003057  37.656918  2116300   \n",
       "5 2015-01-09        A  37.758228  37.758228  37.104367  37.380646  1644900   \n",
       "6 2015-01-12        A  37.399065  37.500368  36.791250  36.938599  2770800   \n",
       "7 2015-01-13        A  37.270130  37.481944  36.220268  36.422871  2013100   \n",
       "8 2015-01-14        A  35.943981  36.008446  35.188817  35.971611  5134000   \n",
       "9 2015-01-15        A  36.220261  36.293934  34.986212  35.004627  2628900   \n",
       "\n",
       "   Return_1d  Return_5d  Return_10d  Return_50d  Volatility_5d  \\\n",
       "0        NaN        NaN         NaN         NaN            NaN   \n",
       "1  -0.018738        NaN         NaN         NaN            NaN   \n",
       "2  -0.015578        NaN         NaN         NaN            NaN   \n",
       "3   0.013272        NaN         NaN         NaN            NaN   \n",
       "4   0.029974        NaN         NaN         NaN            NaN   \n",
       "5  -0.007337   0.000740         NaN         NaN       0.020747   \n",
       "6  -0.011826   0.007789         NaN         NaN       0.019342   \n",
       "7  -0.013962   0.009444         NaN         NaN       0.018992   \n",
       "8  -0.012389  -0.016121         NaN         NaN       0.018657   \n",
       "9  -0.026882  -0.070433         NaN         NaN       0.007357   \n",
       "\n",
       "   Volatility_10d  Volatility_20d     SMA_10  SMA_50  SMA_200  RSI_14  \\\n",
       "0             NaN             NaN        NaN     NaN      NaN     NaN   \n",
       "1             NaN             NaN        NaN     NaN      NaN     NaN   \n",
       "2             NaN             NaN        NaN     NaN      NaN     NaN   \n",
       "3             NaN             NaN        NaN     NaN      NaN     NaN   \n",
       "4             NaN             NaN        NaN     NaN      NaN     NaN   \n",
       "5             NaN             NaN        NaN     NaN      NaN     NaN   \n",
       "6             NaN             NaN        NaN     NaN      NaN     NaN   \n",
       "7             NaN             NaN        NaN     NaN      NaN     NaN   \n",
       "8             NaN             NaN        NaN     NaN      NaN     NaN   \n",
       "9             NaN             NaN  36.602454     NaN      NaN     NaN   \n",
       "\n",
       "   Volume_Change_5d  Volume_Change_10d  \n",
       "0               NaN                NaN  \n",
       "1               NaN                NaN  \n",
       "2               NaN                NaN  \n",
       "3               NaN                NaN  \n",
       "4               NaN                NaN  \n",
       "5          0.075660                NaN  \n",
       "6          0.357038                NaN  \n",
       "7         -0.032443                NaN  \n",
       "8          0.528113                NaN  \n",
       "9          0.242215                NaN  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load the merged dataset\n",
    "file_path = \"/home/jesse/Projects/CWP_RL/03_XGBoost_Return_Prediction/SP500_15_22/15_22_merged_stocks.csv\"\n",
    "df = pd.read_csv(file_path, parse_dates=[\"Date\"])\n",
    "\n",
    "# Ensure sorting by Date and Stock_ID\n",
    "df = df.sort_values(by=[\"Stock_ID\", \"Date\"]).reset_index(drop=True)\n",
    "\n",
    "# Function to calculate technical indicators\n",
    "def calculate_features(df):\n",
    "    df[\"Return_1d\"] = df.groupby(\"Stock_ID\")['Close'].pct_change(1)\n",
    "    df[\"Return_5d\"] = df.groupby(\"Stock_ID\")['Close'].pct_change(5)\n",
    "    df[\"Return_10d\"] = df.groupby(\"Stock_ID\")['Close'].pct_change(10)\n",
    "    df[\"Return_50d\"] = df.groupby(\"Stock_ID\")['Close'].pct_change(50)\n",
    "    \n",
    "    # Rolling volatility\n",
    "    df[\"Volatility_5d\"] = df.groupby(\"Stock_ID\")[\"Return_1d\"].rolling(5).std().reset_index(level=0, drop=True)\n",
    "    df[\"Volatility_10d\"] = df.groupby(\"Stock_ID\")[\"Return_1d\"].rolling(10).std().reset_index(level=0, drop=True)\n",
    "    df[\"Volatility_20d\"] = df.groupby(\"Stock_ID\")[\"Return_1d\"].rolling(20).std().reset_index(level=0, drop=True)\n",
    "    \n",
    "    # Momentum indicators\n",
    "    df[\"SMA_10\"] = df.groupby(\"Stock_ID\")[\"Close\"].rolling(10).mean().reset_index(level=0, drop=True)\n",
    "    df[\"SMA_50\"] = df.groupby(\"Stock_ID\")[\"Close\"].rolling(50).mean().reset_index(level=0, drop=True)\n",
    "    df[\"SMA_200\"] = df.groupby(\"Stock_ID\")[\"Close\"].rolling(200).mean().reset_index(level=0, drop=True)\n",
    "    df[\"RSI_14\"] = 100 - (100 / (1 + df.groupby(\"Stock_ID\")[\"Return_1d\"].rolling(14).apply(lambda x: np.mean(x[x > 0]) / np.mean(-x[x < 0]) if np.mean(-x[x < 0]) != 0 else np.inf).reset_index(level=0, drop=True)))\n",
    "    \n",
    "    # Volume-based features\n",
    "    df[\"Volume_Change_5d\"] = df.groupby(\"Stock_ID\")[\"Volume\"].pct_change(5)\n",
    "    df[\"Volume_Change_10d\"] = df.groupby(\"Stock_ID\")[\"Volume\"].pct_change(10)\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Apply feature calculations\n",
    "df = calculate_features(df)\n",
    "\n",
    "# Save the new dataset with features\n",
    "output_path = \"/home/jesse/Projects/CWP_RL/03_XGBoost_Return_Prediction/SP500_15_22/15_22_merged_stocks_features.csv\"\n",
    "df.to_csv(output_path, index=False)\n",
    "print(f\"Feature engineering complete. Saved to {output_path}\")\n",
    "\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned dataset saved as '/home/jesse/Projects/CWP_RL/03_XGBoost_Return_Prediction/SP500_15_22/15_22_merged_stocks_features.csv'.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Stock_ID</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Return_1d</th>\n",
       "      <th>Return_5d</th>\n",
       "      <th>Return_10d</th>\n",
       "      <th>Return_50d</th>\n",
       "      <th>Volatility_5d</th>\n",
       "      <th>Volatility_10d</th>\n",
       "      <th>Volatility_20d</th>\n",
       "      <th>SMA_10</th>\n",
       "      <th>SMA_50</th>\n",
       "      <th>SMA_200</th>\n",
       "      <th>RSI_14</th>\n",
       "      <th>Volume_Change_5d</th>\n",
       "      <th>Volume_Change_10d</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-10-16</td>\n",
       "      <td>A</td>\n",
       "      <td>33.127384</td>\n",
       "      <td>33.433691</td>\n",
       "      <td>32.830361</td>\n",
       "      <td>33.210922</td>\n",
       "      <td>1754300</td>\n",
       "      <td>0.005621</td>\n",
       "      <td>-0.012421</td>\n",
       "      <td>0.032016</td>\n",
       "      <td>-0.105587</td>\n",
       "      <td>0.012645</td>\n",
       "      <td>0.013504</td>\n",
       "      <td>0.015683</td>\n",
       "      <td>33.048491</td>\n",
       "      <td>33.453844</td>\n",
       "      <td>36.613815</td>\n",
       "      <td>54.321687</td>\n",
       "      <td>-0.457360</td>\n",
       "      <td>-0.501534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-10-19</td>\n",
       "      <td>A</td>\n",
       "      <td>33.127385</td>\n",
       "      <td>33.628613</td>\n",
       "      <td>33.034566</td>\n",
       "      <td>33.628613</td>\n",
       "      <td>3685800</td>\n",
       "      <td>0.012577</td>\n",
       "      <td>0.006668</td>\n",
       "      <td>0.025184</td>\n",
       "      <td>-0.091394</td>\n",
       "      <td>0.013907</td>\n",
       "      <td>0.012759</td>\n",
       "      <td>0.015913</td>\n",
       "      <td>33.131100</td>\n",
       "      <td>33.386192</td>\n",
       "      <td>36.595193</td>\n",
       "      <td>54.596020</td>\n",
       "      <td>1.730424</td>\n",
       "      <td>1.199952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-10-20</td>\n",
       "      <td>A</td>\n",
       "      <td>33.517234</td>\n",
       "      <td>33.897795</td>\n",
       "      <td>33.442976</td>\n",
       "      <td>33.712154</td>\n",
       "      <td>2635800</td>\n",
       "      <td>0.002484</td>\n",
       "      <td>0.019366</td>\n",
       "      <td>0.040688</td>\n",
       "      <td>-0.099940</td>\n",
       "      <td>0.012383</td>\n",
       "      <td>0.011631</td>\n",
       "      <td>0.015275</td>\n",
       "      <td>33.262904</td>\n",
       "      <td>33.311326</td>\n",
       "      <td>36.580488</td>\n",
       "      <td>51.671767</td>\n",
       "      <td>0.105992</td>\n",
       "      <td>0.437422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-10-21</td>\n",
       "      <td>A</td>\n",
       "      <td>33.916350</td>\n",
       "      <td>33.972039</td>\n",
       "      <td>33.229482</td>\n",
       "      <td>33.322304</td>\n",
       "      <td>2886400</td>\n",
       "      <td>-0.011564</td>\n",
       "      <td>0.024251</td>\n",
       "      <td>0.010130</td>\n",
       "      <td>-0.086652</td>\n",
       "      <td>0.010498</td>\n",
       "      <td>0.011392</td>\n",
       "      <td>0.015544</td>\n",
       "      <td>33.296320</td>\n",
       "      <td>33.248099</td>\n",
       "      <td>36.566689</td>\n",
       "      <td>54.018570</td>\n",
       "      <td>0.752094</td>\n",
       "      <td>-0.064497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-10-22</td>\n",
       "      <td>A</td>\n",
       "      <td>33.442976</td>\n",
       "      <td>34.296920</td>\n",
       "      <td>33.415131</td>\n",
       "      <td>33.498669</td>\n",
       "      <td>3696200</td>\n",
       "      <td>0.005293</td>\n",
       "      <td>0.014334</td>\n",
       "      <td>0.002222</td>\n",
       "      <td>-0.069304</td>\n",
       "      <td>0.008890</td>\n",
       "      <td>0.010707</td>\n",
       "      <td>0.015252</td>\n",
       "      <td>33.303746</td>\n",
       "      <td>33.198209</td>\n",
       "      <td>36.551377</td>\n",
       "      <td>48.912329</td>\n",
       "      <td>1.579344</td>\n",
       "      <td>0.422765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2015-10-23</td>\n",
       "      <td>A</td>\n",
       "      <td>33.879222</td>\n",
       "      <td>34.593935</td>\n",
       "      <td>33.582199</td>\n",
       "      <td>34.445423</td>\n",
       "      <td>2732600</td>\n",
       "      <td>0.028262</td>\n",
       "      <td>0.037172</td>\n",
       "      <td>0.024289</td>\n",
       "      <td>-0.034810</td>\n",
       "      <td>0.014580</td>\n",
       "      <td>0.013873</td>\n",
       "      <td>0.016288</td>\n",
       "      <td>33.385427</td>\n",
       "      <td>33.173363</td>\n",
       "      <td>36.535320</td>\n",
       "      <td>51.091822</td>\n",
       "      <td>0.557658</td>\n",
       "      <td>-0.154753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2015-10-26</td>\n",
       "      <td>A</td>\n",
       "      <td>34.324755</td>\n",
       "      <td>34.445422</td>\n",
       "      <td>34.055577</td>\n",
       "      <td>34.185528</td>\n",
       "      <td>1948400</td>\n",
       "      <td>-0.007545</td>\n",
       "      <td>0.016561</td>\n",
       "      <td>0.023339</td>\n",
       "      <td>-0.044323</td>\n",
       "      <td>0.015543</td>\n",
       "      <td>0.013943</td>\n",
       "      <td>0.014333</td>\n",
       "      <td>33.463394</td>\n",
       "      <td>33.141654</td>\n",
       "      <td>36.519344</td>\n",
       "      <td>53.340019</td>\n",
       "      <td>-0.471377</td>\n",
       "      <td>0.443366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2015-10-27</td>\n",
       "      <td>A</td>\n",
       "      <td>34.037012</td>\n",
       "      <td>34.399013</td>\n",
       "      <td>33.851376</td>\n",
       "      <td>34.389729</td>\n",
       "      <td>2557200</td>\n",
       "      <td>0.005973</td>\n",
       "      <td>0.020099</td>\n",
       "      <td>0.039854</td>\n",
       "      <td>-0.042825</td>\n",
       "      <td>0.015570</td>\n",
       "      <td>0.013263</td>\n",
       "      <td>0.014265</td>\n",
       "      <td>33.595197</td>\n",
       "      <td>33.110881</td>\n",
       "      <td>36.506600</td>\n",
       "      <td>50.276063</td>\n",
       "      <td>-0.029820</td>\n",
       "      <td>0.073011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2015-10-28</td>\n",
       "      <td>A</td>\n",
       "      <td>34.399015</td>\n",
       "      <td>34.909523</td>\n",
       "      <td>34.129837</td>\n",
       "      <td>34.825985</td>\n",
       "      <td>1780100</td>\n",
       "      <td>0.012686</td>\n",
       "      <td>0.045125</td>\n",
       "      <td>0.070471</td>\n",
       "      <td>-0.035651</td>\n",
       "      <td>0.013050</td>\n",
       "      <td>0.011372</td>\n",
       "      <td>0.014079</td>\n",
       "      <td>33.824462</td>\n",
       "      <td>33.085132</td>\n",
       "      <td>36.498615</td>\n",
       "      <td>50.133260</td>\n",
       "      <td>-0.383280</td>\n",
       "      <td>0.080551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2015-10-29</td>\n",
       "      <td>A</td>\n",
       "      <td>34.779576</td>\n",
       "      <td>35.058035</td>\n",
       "      <td>34.603216</td>\n",
       "      <td>34.993061</td>\n",
       "      <td>1352300</td>\n",
       "      <td>0.004797</td>\n",
       "      <td>0.044611</td>\n",
       "      <td>0.059584</td>\n",
       "      <td>-0.015379</td>\n",
       "      <td>0.013087</td>\n",
       "      <td>0.011004</td>\n",
       "      <td>0.013119</td>\n",
       "      <td>34.021239</td>\n",
       "      <td>33.074200</td>\n",
       "      <td>36.493723</td>\n",
       "      <td>49.782379</td>\n",
       "      <td>-0.634138</td>\n",
       "      <td>-0.056315</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Date Stock_ID       Open       High        Low      Close   Volume  \\\n",
       "0 2015-10-16        A  33.127384  33.433691  32.830361  33.210922  1754300   \n",
       "1 2015-10-19        A  33.127385  33.628613  33.034566  33.628613  3685800   \n",
       "2 2015-10-20        A  33.517234  33.897795  33.442976  33.712154  2635800   \n",
       "3 2015-10-21        A  33.916350  33.972039  33.229482  33.322304  2886400   \n",
       "4 2015-10-22        A  33.442976  34.296920  33.415131  33.498669  3696200   \n",
       "5 2015-10-23        A  33.879222  34.593935  33.582199  34.445423  2732600   \n",
       "6 2015-10-26        A  34.324755  34.445422  34.055577  34.185528  1948400   \n",
       "7 2015-10-27        A  34.037012  34.399013  33.851376  34.389729  2557200   \n",
       "8 2015-10-28        A  34.399015  34.909523  34.129837  34.825985  1780100   \n",
       "9 2015-10-29        A  34.779576  35.058035  34.603216  34.993061  1352300   \n",
       "\n",
       "   Return_1d  Return_5d  Return_10d  Return_50d  Volatility_5d  \\\n",
       "0   0.005621  -0.012421    0.032016   -0.105587       0.012645   \n",
       "1   0.012577   0.006668    0.025184   -0.091394       0.013907   \n",
       "2   0.002484   0.019366    0.040688   -0.099940       0.012383   \n",
       "3  -0.011564   0.024251    0.010130   -0.086652       0.010498   \n",
       "4   0.005293   0.014334    0.002222   -0.069304       0.008890   \n",
       "5   0.028262   0.037172    0.024289   -0.034810       0.014580   \n",
       "6  -0.007545   0.016561    0.023339   -0.044323       0.015543   \n",
       "7   0.005973   0.020099    0.039854   -0.042825       0.015570   \n",
       "8   0.012686   0.045125    0.070471   -0.035651       0.013050   \n",
       "9   0.004797   0.044611    0.059584   -0.015379       0.013087   \n",
       "\n",
       "   Volatility_10d  Volatility_20d     SMA_10     SMA_50    SMA_200     RSI_14  \\\n",
       "0        0.013504        0.015683  33.048491  33.453844  36.613815  54.321687   \n",
       "1        0.012759        0.015913  33.131100  33.386192  36.595193  54.596020   \n",
       "2        0.011631        0.015275  33.262904  33.311326  36.580488  51.671767   \n",
       "3        0.011392        0.015544  33.296320  33.248099  36.566689  54.018570   \n",
       "4        0.010707        0.015252  33.303746  33.198209  36.551377  48.912329   \n",
       "5        0.013873        0.016288  33.385427  33.173363  36.535320  51.091822   \n",
       "6        0.013943        0.014333  33.463394  33.141654  36.519344  53.340019   \n",
       "7        0.013263        0.014265  33.595197  33.110881  36.506600  50.276063   \n",
       "8        0.011372        0.014079  33.824462  33.085132  36.498615  50.133260   \n",
       "9        0.011004        0.013119  34.021239  33.074200  36.493723  49.782379   \n",
       "\n",
       "   Volume_Change_5d  Volume_Change_10d  \n",
       "0         -0.457360          -0.501534  \n",
       "1          1.730424           1.199952  \n",
       "2          0.105992           0.437422  \n",
       "3          0.752094          -0.064497  \n",
       "4          1.579344           0.422765  \n",
       "5          0.557658          -0.154753  \n",
       "6         -0.471377           0.443366  \n",
       "7         -0.029820           0.073011  \n",
       "8         -0.383280           0.080551  \n",
       "9         -0.634138          -0.056315  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop rows with NaN values\n",
    "df = df.dropna().reset_index(drop=True)\n",
    "\n",
    "# Save the cleaned dataset\n",
    "training_csv_path = \"/home/jesse/Projects/CWP_RL/03_XGBoost_Return_Prediction/SP500_15_22/15_22_merged_stocks_features.csv\"\n",
    "df.to_csv(training_csv_path, index=False)\n",
    "\n",
    "print(f\"Cleaned dataset saved as '{training_csv_path}'.\")\n",
    "\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalized dataframe saved at /home/jesse/Projects/CWP_RL/03_XGBoost_Return_Prediction/SP500_15_22/15_22_merged_stocks_normalized.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataframe\n",
    "csv_path = \"/home/jesse/Projects/CWP_RL/03_XGBoost_Return_Prediction/SP500_15_22/15_22_merged_stocks_features.csv\"\n",
    "df = pd.read_csv(csv_path)\n",
    "\n",
    "# Normalize 'Volume_Change_5d' and 'Volume_Change_10d' to range 1-1000\n",
    "def normalize_column(df, column_name, new_min=1, new_max=1000):\n",
    "    min_val = df[column_name].min()\n",
    "    max_val = df[column_name].max()\n",
    "    df[column_name] = (df[column_name] - min_val) * (new_max - new_min) / (max_val - min_val) + new_min\n",
    "\n",
    "# Normalize the two columns\n",
    "normalize_column(df, 'Volume_Change_5d')\n",
    "normalize_column(df, 'Volume_Change_10d')\n",
    "\n",
    "# Save the normalized dataframe to a new file\n",
    "normalized_csv_path = \"/home/jesse/Projects/CWP_RL/03_XGBoost_Return_Prediction/SP500_15_22/15_22_merged_stocks_normalized.csv\"\n",
    "df.to_csv(normalized_csv_path, index=False)\n",
    "\n",
    "print(f\"Normalized dataframe saved at {normalized_csv_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Stock_ID</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Return_1d</th>\n",
       "      <th>Return_5d</th>\n",
       "      <th>Return_10d</th>\n",
       "      <th>Return_50d</th>\n",
       "      <th>Volatility_5d</th>\n",
       "      <th>Volatility_10d</th>\n",
       "      <th>Volatility_20d</th>\n",
       "      <th>SMA_10</th>\n",
       "      <th>SMA_50</th>\n",
       "      <th>SMA_200</th>\n",
       "      <th>RSI_14</th>\n",
       "      <th>Volume_Change_5d</th>\n",
       "      <th>Volume_Change_10d</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-10-16</td>\n",
       "      <td>A</td>\n",
       "      <td>33.127384</td>\n",
       "      <td>33.433691</td>\n",
       "      <td>32.830361</td>\n",
       "      <td>33.210922</td>\n",
       "      <td>1754300</td>\n",
       "      <td>0.005621</td>\n",
       "      <td>-0.012421</td>\n",
       "      <td>0.032016</td>\n",
       "      <td>-0.105587</td>\n",
       "      <td>0.012645</td>\n",
       "      <td>0.013504</td>\n",
       "      <td>0.015683</td>\n",
       "      <td>33.048491</td>\n",
       "      <td>33.453844</td>\n",
       "      <td>36.613815</td>\n",
       "      <td>54.321687</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-10-19</td>\n",
       "      <td>A</td>\n",
       "      <td>33.127385</td>\n",
       "      <td>33.628613</td>\n",
       "      <td>33.034566</td>\n",
       "      <td>33.628613</td>\n",
       "      <td>3685800</td>\n",
       "      <td>0.012577</td>\n",
       "      <td>0.006668</td>\n",
       "      <td>0.025184</td>\n",
       "      <td>-0.091394</td>\n",
       "      <td>0.013907</td>\n",
       "      <td>0.012759</td>\n",
       "      <td>0.015913</td>\n",
       "      <td>33.131100</td>\n",
       "      <td>33.386192</td>\n",
       "      <td>36.595193</td>\n",
       "      <td>54.596020</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-10-20</td>\n",
       "      <td>A</td>\n",
       "      <td>33.517234</td>\n",
       "      <td>33.897795</td>\n",
       "      <td>33.442976</td>\n",
       "      <td>33.712154</td>\n",
       "      <td>2635800</td>\n",
       "      <td>0.002484</td>\n",
       "      <td>0.019366</td>\n",
       "      <td>0.040688</td>\n",
       "      <td>-0.099940</td>\n",
       "      <td>0.012383</td>\n",
       "      <td>0.011631</td>\n",
       "      <td>0.015275</td>\n",
       "      <td>33.262904</td>\n",
       "      <td>33.311326</td>\n",
       "      <td>36.580488</td>\n",
       "      <td>51.671767</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-10-21</td>\n",
       "      <td>A</td>\n",
       "      <td>33.916350</td>\n",
       "      <td>33.972039</td>\n",
       "      <td>33.229482</td>\n",
       "      <td>33.322304</td>\n",
       "      <td>2886400</td>\n",
       "      <td>-0.011564</td>\n",
       "      <td>0.024251</td>\n",
       "      <td>0.010130</td>\n",
       "      <td>-0.086652</td>\n",
       "      <td>0.010498</td>\n",
       "      <td>0.011392</td>\n",
       "      <td>0.015544</td>\n",
       "      <td>33.296320</td>\n",
       "      <td>33.248099</td>\n",
       "      <td>36.566689</td>\n",
       "      <td>54.018570</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-10-22</td>\n",
       "      <td>A</td>\n",
       "      <td>33.442976</td>\n",
       "      <td>34.296920</td>\n",
       "      <td>33.415131</td>\n",
       "      <td>33.498669</td>\n",
       "      <td>3696200</td>\n",
       "      <td>0.005293</td>\n",
       "      <td>0.014334</td>\n",
       "      <td>0.002222</td>\n",
       "      <td>-0.069304</td>\n",
       "      <td>0.008890</td>\n",
       "      <td>0.010707</td>\n",
       "      <td>0.015252</td>\n",
       "      <td>33.303746</td>\n",
       "      <td>33.198209</td>\n",
       "      <td>36.551377</td>\n",
       "      <td>48.912329</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2015-10-23</td>\n",
       "      <td>A</td>\n",
       "      <td>33.879222</td>\n",
       "      <td>34.593935</td>\n",
       "      <td>33.582199</td>\n",
       "      <td>34.445423</td>\n",
       "      <td>2732600</td>\n",
       "      <td>0.028262</td>\n",
       "      <td>0.037172</td>\n",
       "      <td>0.024289</td>\n",
       "      <td>-0.034810</td>\n",
       "      <td>0.014580</td>\n",
       "      <td>0.013873</td>\n",
       "      <td>0.016288</td>\n",
       "      <td>33.385427</td>\n",
       "      <td>33.173363</td>\n",
       "      <td>36.535320</td>\n",
       "      <td>51.091822</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2015-10-26</td>\n",
       "      <td>A</td>\n",
       "      <td>34.324755</td>\n",
       "      <td>34.445422</td>\n",
       "      <td>34.055577</td>\n",
       "      <td>34.185528</td>\n",
       "      <td>1948400</td>\n",
       "      <td>-0.007545</td>\n",
       "      <td>0.016561</td>\n",
       "      <td>0.023339</td>\n",
       "      <td>-0.044323</td>\n",
       "      <td>0.015543</td>\n",
       "      <td>0.013943</td>\n",
       "      <td>0.014333</td>\n",
       "      <td>33.463394</td>\n",
       "      <td>33.141654</td>\n",
       "      <td>36.519344</td>\n",
       "      <td>53.340019</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2015-10-27</td>\n",
       "      <td>A</td>\n",
       "      <td>34.037012</td>\n",
       "      <td>34.399013</td>\n",
       "      <td>33.851376</td>\n",
       "      <td>34.389729</td>\n",
       "      <td>2557200</td>\n",
       "      <td>0.005973</td>\n",
       "      <td>0.020099</td>\n",
       "      <td>0.039854</td>\n",
       "      <td>-0.042825</td>\n",
       "      <td>0.015570</td>\n",
       "      <td>0.013263</td>\n",
       "      <td>0.014265</td>\n",
       "      <td>33.595197</td>\n",
       "      <td>33.110881</td>\n",
       "      <td>36.506600</td>\n",
       "      <td>50.276063</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2015-10-28</td>\n",
       "      <td>A</td>\n",
       "      <td>34.399015</td>\n",
       "      <td>34.909523</td>\n",
       "      <td>34.129837</td>\n",
       "      <td>34.825985</td>\n",
       "      <td>1780100</td>\n",
       "      <td>0.012686</td>\n",
       "      <td>0.045125</td>\n",
       "      <td>0.070471</td>\n",
       "      <td>-0.035651</td>\n",
       "      <td>0.013050</td>\n",
       "      <td>0.011372</td>\n",
       "      <td>0.014079</td>\n",
       "      <td>33.824462</td>\n",
       "      <td>33.085132</td>\n",
       "      <td>36.498615</td>\n",
       "      <td>50.133260</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2015-10-29</td>\n",
       "      <td>A</td>\n",
       "      <td>34.779576</td>\n",
       "      <td>35.058035</td>\n",
       "      <td>34.603216</td>\n",
       "      <td>34.993061</td>\n",
       "      <td>1352300</td>\n",
       "      <td>0.004797</td>\n",
       "      <td>0.044611</td>\n",
       "      <td>0.059584</td>\n",
       "      <td>-0.015379</td>\n",
       "      <td>0.013087</td>\n",
       "      <td>0.011004</td>\n",
       "      <td>0.013119</td>\n",
       "      <td>34.021239</td>\n",
       "      <td>33.074200</td>\n",
       "      <td>36.493723</td>\n",
       "      <td>49.782379</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date Stock_ID       Open       High        Low      Close   Volume  \\\n",
       "0  2015-10-16        A  33.127384  33.433691  32.830361  33.210922  1754300   \n",
       "1  2015-10-19        A  33.127385  33.628613  33.034566  33.628613  3685800   \n",
       "2  2015-10-20        A  33.517234  33.897795  33.442976  33.712154  2635800   \n",
       "3  2015-10-21        A  33.916350  33.972039  33.229482  33.322304  2886400   \n",
       "4  2015-10-22        A  33.442976  34.296920  33.415131  33.498669  3696200   \n",
       "5  2015-10-23        A  33.879222  34.593935  33.582199  34.445423  2732600   \n",
       "6  2015-10-26        A  34.324755  34.445422  34.055577  34.185528  1948400   \n",
       "7  2015-10-27        A  34.037012  34.399013  33.851376  34.389729  2557200   \n",
       "8  2015-10-28        A  34.399015  34.909523  34.129837  34.825985  1780100   \n",
       "9  2015-10-29        A  34.779576  35.058035  34.603216  34.993061  1352300   \n",
       "\n",
       "   Return_1d  Return_5d  Return_10d  Return_50d  Volatility_5d  \\\n",
       "0   0.005621  -0.012421    0.032016   -0.105587       0.012645   \n",
       "1   0.012577   0.006668    0.025184   -0.091394       0.013907   \n",
       "2   0.002484   0.019366    0.040688   -0.099940       0.012383   \n",
       "3  -0.011564   0.024251    0.010130   -0.086652       0.010498   \n",
       "4   0.005293   0.014334    0.002222   -0.069304       0.008890   \n",
       "5   0.028262   0.037172    0.024289   -0.034810       0.014580   \n",
       "6  -0.007545   0.016561    0.023339   -0.044323       0.015543   \n",
       "7   0.005973   0.020099    0.039854   -0.042825       0.015570   \n",
       "8   0.012686   0.045125    0.070471   -0.035651       0.013050   \n",
       "9   0.004797   0.044611    0.059584   -0.015379       0.013087   \n",
       "\n",
       "   Volatility_10d  Volatility_20d     SMA_10     SMA_50    SMA_200     RSI_14  \\\n",
       "0        0.013504        0.015683  33.048491  33.453844  36.613815  54.321687   \n",
       "1        0.012759        0.015913  33.131100  33.386192  36.595193  54.596020   \n",
       "2        0.011631        0.015275  33.262904  33.311326  36.580488  51.671767   \n",
       "3        0.011392        0.015544  33.296320  33.248099  36.566689  54.018570   \n",
       "4        0.010707        0.015252  33.303746  33.198209  36.551377  48.912329   \n",
       "5        0.013873        0.016288  33.385427  33.173363  36.535320  51.091822   \n",
       "6        0.013943        0.014333  33.463394  33.141654  36.519344  53.340019   \n",
       "7        0.013263        0.014265  33.595197  33.110881  36.506600  50.276063   \n",
       "8        0.011372        0.014079  33.824462  33.085132  36.498615  50.133260   \n",
       "9        0.011004        0.013119  34.021239  33.074200  36.493723  49.782379   \n",
       "\n",
       "   Volume_Change_5d  Volume_Change_10d  \n",
       "0               1.0                1.0  \n",
       "1               1.0                1.0  \n",
       "2               1.0                1.0  \n",
       "3               1.0                1.0  \n",
       "4               1.0                1.0  \n",
       "5               1.0                1.0  \n",
       "6               1.0                1.0  \n",
       "7               1.0                1.0  \n",
       "8               1.0                1.0  \n",
       "9               1.0                1.0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set saved: /home/jesse/Projects/CWP_RL/03_XGBoost_Return_Prediction/SP500_15_22/15_22_training_set.csv (751921 rows)\n",
      "Validation set saved: /home/jesse/Projects/CWP_RL/03_XGBoost_Return_Prediction/SP500_15_22/15_22_validation_set.csv (124284 rows)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the merged dataset\n",
    "file_path = \"/home/jesse/Projects/CWP_RL/03_XGBoost_Return_Prediction/SP500_15_22/15_22_merged_stocks_normalized.csv\"\n",
    "df = pd.read_csv(file_path, parse_dates=[\"Date\"])\n",
    "\n",
    "# Define split dates\n",
    "train_end_date = \"2021-12-31\"\n",
    "valid_start_date = \"2022-01-01\"\n",
    "\n",
    "# Split into training and validation sets\n",
    "train_df = df[df[\"Date\"] <= train_end_date]\n",
    "valid_df = df[df[\"Date\"] >= valid_start_date]\n",
    "\n",
    "# Save to CSV\n",
    "train_path = \"/home/jesse/Projects/CWP_RL/03_XGBoost_Return_Prediction/SP500_15_22/15_22_training_set.csv\"\n",
    "valid_path = \"/home/jesse/Projects/CWP_RL/03_XGBoost_Return_Prediction/SP500_15_22/15_22_validation_set.csv\"\n",
    "\n",
    "train_df.to_csv(train_path, index=False)\n",
    "valid_df.to_csv(valid_path, index=False)\n",
    "\n",
    "print(f\"Training set saved: {train_path} ({len(train_df)} rows)\")\n",
    "print(f\"Validation set saved: {valid_path} ({len(valid_df)} rows)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Stock_ID</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Return_1d</th>\n",
       "      <th>Return_5d</th>\n",
       "      <th>Return_10d</th>\n",
       "      <th>Return_50d</th>\n",
       "      <th>Volatility_5d</th>\n",
       "      <th>Volatility_10d</th>\n",
       "      <th>Volatility_20d</th>\n",
       "      <th>SMA_10</th>\n",
       "      <th>SMA_50</th>\n",
       "      <th>SMA_200</th>\n",
       "      <th>RSI_14</th>\n",
       "      <th>Volume_Change_5d</th>\n",
       "      <th>Volume_Change_10d</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-10-16</td>\n",
       "      <td>A</td>\n",
       "      <td>33.127384</td>\n",
       "      <td>33.433691</td>\n",
       "      <td>32.830361</td>\n",
       "      <td>33.210922</td>\n",
       "      <td>1754300</td>\n",
       "      <td>0.005621</td>\n",
       "      <td>-0.012421</td>\n",
       "      <td>0.032016</td>\n",
       "      <td>-0.105587</td>\n",
       "      <td>0.012645</td>\n",
       "      <td>0.013504</td>\n",
       "      <td>0.015683</td>\n",
       "      <td>33.048491</td>\n",
       "      <td>33.453844</td>\n",
       "      <td>36.613815</td>\n",
       "      <td>54.321687</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-10-19</td>\n",
       "      <td>A</td>\n",
       "      <td>33.127385</td>\n",
       "      <td>33.628613</td>\n",
       "      <td>33.034566</td>\n",
       "      <td>33.628613</td>\n",
       "      <td>3685800</td>\n",
       "      <td>0.012577</td>\n",
       "      <td>0.006668</td>\n",
       "      <td>0.025184</td>\n",
       "      <td>-0.091394</td>\n",
       "      <td>0.013907</td>\n",
       "      <td>0.012759</td>\n",
       "      <td>0.015913</td>\n",
       "      <td>33.131100</td>\n",
       "      <td>33.386192</td>\n",
       "      <td>36.595193</td>\n",
       "      <td>54.596020</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-10-20</td>\n",
       "      <td>A</td>\n",
       "      <td>33.517234</td>\n",
       "      <td>33.897795</td>\n",
       "      <td>33.442976</td>\n",
       "      <td>33.712154</td>\n",
       "      <td>2635800</td>\n",
       "      <td>0.002484</td>\n",
       "      <td>0.019366</td>\n",
       "      <td>0.040688</td>\n",
       "      <td>-0.099940</td>\n",
       "      <td>0.012383</td>\n",
       "      <td>0.011631</td>\n",
       "      <td>0.015275</td>\n",
       "      <td>33.262904</td>\n",
       "      <td>33.311326</td>\n",
       "      <td>36.580488</td>\n",
       "      <td>51.671767</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-10-21</td>\n",
       "      <td>A</td>\n",
       "      <td>33.916350</td>\n",
       "      <td>33.972039</td>\n",
       "      <td>33.229482</td>\n",
       "      <td>33.322304</td>\n",
       "      <td>2886400</td>\n",
       "      <td>-0.011564</td>\n",
       "      <td>0.024251</td>\n",
       "      <td>0.010130</td>\n",
       "      <td>-0.086652</td>\n",
       "      <td>0.010498</td>\n",
       "      <td>0.011392</td>\n",
       "      <td>0.015544</td>\n",
       "      <td>33.296320</td>\n",
       "      <td>33.248099</td>\n",
       "      <td>36.566689</td>\n",
       "      <td>54.018570</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-10-22</td>\n",
       "      <td>A</td>\n",
       "      <td>33.442976</td>\n",
       "      <td>34.296920</td>\n",
       "      <td>33.415131</td>\n",
       "      <td>33.498669</td>\n",
       "      <td>3696200</td>\n",
       "      <td>0.005293</td>\n",
       "      <td>0.014334</td>\n",
       "      <td>0.002222</td>\n",
       "      <td>-0.069304</td>\n",
       "      <td>0.008890</td>\n",
       "      <td>0.010707</td>\n",
       "      <td>0.015252</td>\n",
       "      <td>33.303746</td>\n",
       "      <td>33.198209</td>\n",
       "      <td>36.551377</td>\n",
       "      <td>48.912329</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2015-10-23</td>\n",
       "      <td>A</td>\n",
       "      <td>33.879222</td>\n",
       "      <td>34.593935</td>\n",
       "      <td>33.582199</td>\n",
       "      <td>34.445423</td>\n",
       "      <td>2732600</td>\n",
       "      <td>0.028262</td>\n",
       "      <td>0.037172</td>\n",
       "      <td>0.024289</td>\n",
       "      <td>-0.034810</td>\n",
       "      <td>0.014580</td>\n",
       "      <td>0.013873</td>\n",
       "      <td>0.016288</td>\n",
       "      <td>33.385427</td>\n",
       "      <td>33.173363</td>\n",
       "      <td>36.535320</td>\n",
       "      <td>51.091822</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2015-10-26</td>\n",
       "      <td>A</td>\n",
       "      <td>34.324755</td>\n",
       "      <td>34.445422</td>\n",
       "      <td>34.055577</td>\n",
       "      <td>34.185528</td>\n",
       "      <td>1948400</td>\n",
       "      <td>-0.007545</td>\n",
       "      <td>0.016561</td>\n",
       "      <td>0.023339</td>\n",
       "      <td>-0.044323</td>\n",
       "      <td>0.015543</td>\n",
       "      <td>0.013943</td>\n",
       "      <td>0.014333</td>\n",
       "      <td>33.463394</td>\n",
       "      <td>33.141654</td>\n",
       "      <td>36.519344</td>\n",
       "      <td>53.340019</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2015-10-27</td>\n",
       "      <td>A</td>\n",
       "      <td>34.037012</td>\n",
       "      <td>34.399013</td>\n",
       "      <td>33.851376</td>\n",
       "      <td>34.389729</td>\n",
       "      <td>2557200</td>\n",
       "      <td>0.005973</td>\n",
       "      <td>0.020099</td>\n",
       "      <td>0.039854</td>\n",
       "      <td>-0.042825</td>\n",
       "      <td>0.015570</td>\n",
       "      <td>0.013263</td>\n",
       "      <td>0.014265</td>\n",
       "      <td>33.595197</td>\n",
       "      <td>33.110881</td>\n",
       "      <td>36.506600</td>\n",
       "      <td>50.276063</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2015-10-28</td>\n",
       "      <td>A</td>\n",
       "      <td>34.399015</td>\n",
       "      <td>34.909523</td>\n",
       "      <td>34.129837</td>\n",
       "      <td>34.825985</td>\n",
       "      <td>1780100</td>\n",
       "      <td>0.012686</td>\n",
       "      <td>0.045125</td>\n",
       "      <td>0.070471</td>\n",
       "      <td>-0.035651</td>\n",
       "      <td>0.013050</td>\n",
       "      <td>0.011372</td>\n",
       "      <td>0.014079</td>\n",
       "      <td>33.824462</td>\n",
       "      <td>33.085132</td>\n",
       "      <td>36.498615</td>\n",
       "      <td>50.133260</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2015-10-29</td>\n",
       "      <td>A</td>\n",
       "      <td>34.779576</td>\n",
       "      <td>35.058035</td>\n",
       "      <td>34.603216</td>\n",
       "      <td>34.993061</td>\n",
       "      <td>1352300</td>\n",
       "      <td>0.004797</td>\n",
       "      <td>0.044611</td>\n",
       "      <td>0.059584</td>\n",
       "      <td>-0.015379</td>\n",
       "      <td>0.013087</td>\n",
       "      <td>0.011004</td>\n",
       "      <td>0.013119</td>\n",
       "      <td>34.021239</td>\n",
       "      <td>33.074200</td>\n",
       "      <td>36.493723</td>\n",
       "      <td>49.782379</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Date Stock_ID       Open       High        Low      Close   Volume  \\\n",
       "0 2015-10-16        A  33.127384  33.433691  32.830361  33.210922  1754300   \n",
       "1 2015-10-19        A  33.127385  33.628613  33.034566  33.628613  3685800   \n",
       "2 2015-10-20        A  33.517234  33.897795  33.442976  33.712154  2635800   \n",
       "3 2015-10-21        A  33.916350  33.972039  33.229482  33.322304  2886400   \n",
       "4 2015-10-22        A  33.442976  34.296920  33.415131  33.498669  3696200   \n",
       "5 2015-10-23        A  33.879222  34.593935  33.582199  34.445423  2732600   \n",
       "6 2015-10-26        A  34.324755  34.445422  34.055577  34.185528  1948400   \n",
       "7 2015-10-27        A  34.037012  34.399013  33.851376  34.389729  2557200   \n",
       "8 2015-10-28        A  34.399015  34.909523  34.129837  34.825985  1780100   \n",
       "9 2015-10-29        A  34.779576  35.058035  34.603216  34.993061  1352300   \n",
       "\n",
       "   Return_1d  Return_5d  Return_10d  Return_50d  Volatility_5d  \\\n",
       "0   0.005621  -0.012421    0.032016   -0.105587       0.012645   \n",
       "1   0.012577   0.006668    0.025184   -0.091394       0.013907   \n",
       "2   0.002484   0.019366    0.040688   -0.099940       0.012383   \n",
       "3  -0.011564   0.024251    0.010130   -0.086652       0.010498   \n",
       "4   0.005293   0.014334    0.002222   -0.069304       0.008890   \n",
       "5   0.028262   0.037172    0.024289   -0.034810       0.014580   \n",
       "6  -0.007545   0.016561    0.023339   -0.044323       0.015543   \n",
       "7   0.005973   0.020099    0.039854   -0.042825       0.015570   \n",
       "8   0.012686   0.045125    0.070471   -0.035651       0.013050   \n",
       "9   0.004797   0.044611    0.059584   -0.015379       0.013087   \n",
       "\n",
       "   Volatility_10d  Volatility_20d     SMA_10     SMA_50    SMA_200     RSI_14  \\\n",
       "0        0.013504        0.015683  33.048491  33.453844  36.613815  54.321687   \n",
       "1        0.012759        0.015913  33.131100  33.386192  36.595193  54.596020   \n",
       "2        0.011631        0.015275  33.262904  33.311326  36.580488  51.671767   \n",
       "3        0.011392        0.015544  33.296320  33.248099  36.566689  54.018570   \n",
       "4        0.010707        0.015252  33.303746  33.198209  36.551377  48.912329   \n",
       "5        0.013873        0.016288  33.385427  33.173363  36.535320  51.091822   \n",
       "6        0.013943        0.014333  33.463394  33.141654  36.519344  53.340019   \n",
       "7        0.013263        0.014265  33.595197  33.110881  36.506600  50.276063   \n",
       "8        0.011372        0.014079  33.824462  33.085132  36.498615  50.133260   \n",
       "9        0.011004        0.013119  34.021239  33.074200  36.493723  49.782379   \n",
       "\n",
       "   Volume_Change_5d  Volume_Change_10d  \n",
       "0               1.0                1.0  \n",
       "1               1.0                1.0  \n",
       "2               1.0                1.0  \n",
       "3               1.0                1.0  \n",
       "4               1.0                1.0  \n",
       "5               1.0                1.0  \n",
       "6               1.0                1.0  \n",
       "7               1.0                1.0  \n",
       "8               1.0                1.0  \n",
       "9               1.0                1.0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Stock_ID</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Return_1d</th>\n",
       "      <th>Return_5d</th>\n",
       "      <th>Return_10d</th>\n",
       "      <th>Return_50d</th>\n",
       "      <th>Volatility_5d</th>\n",
       "      <th>Volatility_10d</th>\n",
       "      <th>Volatility_20d</th>\n",
       "      <th>SMA_10</th>\n",
       "      <th>SMA_50</th>\n",
       "      <th>SMA_200</th>\n",
       "      <th>RSI_14</th>\n",
       "      <th>Volume_Change_5d</th>\n",
       "      <th>Volume_Change_10d</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1564</th>\n",
       "      <td>2022-01-03</td>\n",
       "      <td>A</td>\n",
       "      <td>155.740608</td>\n",
       "      <td>156.171591</td>\n",
       "      <td>150.774533</td>\n",
       "      <td>153.272263</td>\n",
       "      <td>1606300</td>\n",
       "      <td>-0.018565</td>\n",
       "      <td>-0.012939</td>\n",
       "      <td>0.034778</td>\n",
       "      <td>-0.001618</td>\n",
       "      <td>0.010788</td>\n",
       "      <td>0.012413</td>\n",
       "      <td>0.014346</td>\n",
       "      <td>154.043616</td>\n",
       "      <td>153.078423</td>\n",
       "      <td>146.846470</td>\n",
       "      <td>36.814534</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1565</th>\n",
       "      <td>2022-01-04</td>\n",
       "      <td>A</td>\n",
       "      <td>152.302601</td>\n",
       "      <td>152.439730</td>\n",
       "      <td>146.631282</td>\n",
       "      <td>148.090744</td>\n",
       "      <td>2234000</td>\n",
       "      <td>-0.033806</td>\n",
       "      <td>-0.048944</td>\n",
       "      <td>0.006443</td>\n",
       "      <td>-0.041659</td>\n",
       "      <td>0.016928</td>\n",
       "      <td>0.017004</td>\n",
       "      <td>0.016179</td>\n",
       "      <td>154.138420</td>\n",
       "      <td>152.949674</td>\n",
       "      <td>146.984801</td>\n",
       "      <td>35.325437</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1566</th>\n",
       "      <td>2022-01-05</td>\n",
       "      <td>A</td>\n",
       "      <td>147.738100</td>\n",
       "      <td>149.961571</td>\n",
       "      <td>145.485246</td>\n",
       "      <td>145.553818</td>\n",
       "      <td>2370500</td>\n",
       "      <td>-0.017131</td>\n",
       "      <td>-0.073789</td>\n",
       "      <td>-0.033543</td>\n",
       "      <td>-0.060277</td>\n",
       "      <td>0.013181</td>\n",
       "      <td>0.015774</td>\n",
       "      <td>0.016196</td>\n",
       "      <td>153.633244</td>\n",
       "      <td>152.762948</td>\n",
       "      <td>147.118386</td>\n",
       "      <td>33.602793</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1567</th>\n",
       "      <td>2022-01-06</td>\n",
       "      <td>A</td>\n",
       "      <td>145.798702</td>\n",
       "      <td>146.885948</td>\n",
       "      <td>142.595730</td>\n",
       "      <td>146.063156</td>\n",
       "      <td>2298300</td>\n",
       "      <td>0.003499</td>\n",
       "      <td>-0.071877</td>\n",
       "      <td>-0.047606</td>\n",
       "      <td>-0.056095</td>\n",
       "      <td>0.013846</td>\n",
       "      <td>0.014128</td>\n",
       "      <td>0.015698</td>\n",
       "      <td>152.903145</td>\n",
       "      <td>152.589342</td>\n",
       "      <td>147.260072</td>\n",
       "      <td>33.329199</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1568</th>\n",
       "      <td>2022-01-07</td>\n",
       "      <td>A</td>\n",
       "      <td>146.063134</td>\n",
       "      <td>146.660630</td>\n",
       "      <td>142.115747</td>\n",
       "      <td>142.174515</td>\n",
       "      <td>2058600</td>\n",
       "      <td>-0.026623</td>\n",
       "      <td>-0.089626</td>\n",
       "      <td>-0.078953</td>\n",
       "      <td>-0.063885</td>\n",
       "      <td>0.014019</td>\n",
       "      <td>0.015044</td>\n",
       "      <td>0.016531</td>\n",
       "      <td>151.684406</td>\n",
       "      <td>152.395288</td>\n",
       "      <td>147.377151</td>\n",
       "      <td>32.621562</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1569</th>\n",
       "      <td>2022-01-10</td>\n",
       "      <td>A</td>\n",
       "      <td>140.352650</td>\n",
       "      <td>142.331245</td>\n",
       "      <td>137.972470</td>\n",
       "      <td>142.184326</td>\n",
       "      <td>2548100</td>\n",
       "      <td>0.000069</td>\n",
       "      <td>-0.072341</td>\n",
       "      <td>-0.084345</td>\n",
       "      <td>-0.066826</td>\n",
       "      <td>0.016297</td>\n",
       "      <td>0.014540</td>\n",
       "      <td>0.016238</td>\n",
       "      <td>150.374692</td>\n",
       "      <td>152.191647</td>\n",
       "      <td>147.476061</td>\n",
       "      <td>27.632004</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1570</th>\n",
       "      <td>2022-01-11</td>\n",
       "      <td>A</td>\n",
       "      <td>142.027622</td>\n",
       "      <td>143.927856</td>\n",
       "      <td>140.862014</td>\n",
       "      <td>143.634003</td>\n",
       "      <td>2194200</td>\n",
       "      <td>0.010196</td>\n",
       "      <td>-0.030095</td>\n",
       "      <td>-0.077565</td>\n",
       "      <td>-0.067667</td>\n",
       "      <td>0.015318</td>\n",
       "      <td>0.015356</td>\n",
       "      <td>0.016509</td>\n",
       "      <td>149.166905</td>\n",
       "      <td>151.983153</td>\n",
       "      <td>147.583290</td>\n",
       "      <td>23.688397</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1571</th>\n",
       "      <td>2022-01-12</td>\n",
       "      <td>A</td>\n",
       "      <td>144.770207</td>\n",
       "      <td>147.307110</td>\n",
       "      <td>144.525332</td>\n",
       "      <td>146.445145</td>\n",
       "      <td>2250800</td>\n",
       "      <td>0.019572</td>\n",
       "      <td>0.006124</td>\n",
       "      <td>-0.068118</td>\n",
       "      <td>-0.046817</td>\n",
       "      <td>0.017313</td>\n",
       "      <td>0.016909</td>\n",
       "      <td>0.016119</td>\n",
       "      <td>148.096439</td>\n",
       "      <td>151.839295</td>\n",
       "      <td>147.707401</td>\n",
       "      <td>24.077675</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1572</th>\n",
       "      <td>2022-01-13</td>\n",
       "      <td>A</td>\n",
       "      <td>146.396189</td>\n",
       "      <td>146.474536</td>\n",
       "      <td>141.880690</td>\n",
       "      <td>142.194122</td>\n",
       "      <td>1741800</td>\n",
       "      <td>-0.029028</td>\n",
       "      <td>-0.026489</td>\n",
       "      <td>-0.096462</td>\n",
       "      <td>-0.079118</td>\n",
       "      <td>0.021824</td>\n",
       "      <td>0.017953</td>\n",
       "      <td>0.016809</td>\n",
       "      <td>146.578369</td>\n",
       "      <td>151.594961</td>\n",
       "      <td>147.799053</td>\n",
       "      <td>22.946890</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1573</th>\n",
       "      <td>2022-01-14</td>\n",
       "      <td>A</td>\n",
       "      <td>141.087292</td>\n",
       "      <td>142.174539</td>\n",
       "      <td>139.441738</td>\n",
       "      <td>141.714172</td>\n",
       "      <td>2225400</td>\n",
       "      <td>-0.003375</td>\n",
       "      <td>-0.003238</td>\n",
       "      <td>-0.092574</td>\n",
       "      <td>-0.084257</td>\n",
       "      <td>0.018301</td>\n",
       "      <td>0.018064</td>\n",
       "      <td>0.016147</td>\n",
       "      <td>145.132626</td>\n",
       "      <td>151.334181</td>\n",
       "      <td>147.885626</td>\n",
       "      <td>25.566777</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Date Stock_ID        Open        High         Low       Close  \\\n",
       "1564 2022-01-03        A  155.740608  156.171591  150.774533  153.272263   \n",
       "1565 2022-01-04        A  152.302601  152.439730  146.631282  148.090744   \n",
       "1566 2022-01-05        A  147.738100  149.961571  145.485246  145.553818   \n",
       "1567 2022-01-06        A  145.798702  146.885948  142.595730  146.063156   \n",
       "1568 2022-01-07        A  146.063134  146.660630  142.115747  142.174515   \n",
       "1569 2022-01-10        A  140.352650  142.331245  137.972470  142.184326   \n",
       "1570 2022-01-11        A  142.027622  143.927856  140.862014  143.634003   \n",
       "1571 2022-01-12        A  144.770207  147.307110  144.525332  146.445145   \n",
       "1572 2022-01-13        A  146.396189  146.474536  141.880690  142.194122   \n",
       "1573 2022-01-14        A  141.087292  142.174539  139.441738  141.714172   \n",
       "\n",
       "       Volume  Return_1d  Return_5d  Return_10d  Return_50d  Volatility_5d  \\\n",
       "1564  1606300  -0.018565  -0.012939    0.034778   -0.001618       0.010788   \n",
       "1565  2234000  -0.033806  -0.048944    0.006443   -0.041659       0.016928   \n",
       "1566  2370500  -0.017131  -0.073789   -0.033543   -0.060277       0.013181   \n",
       "1567  2298300   0.003499  -0.071877   -0.047606   -0.056095       0.013846   \n",
       "1568  2058600  -0.026623  -0.089626   -0.078953   -0.063885       0.014019   \n",
       "1569  2548100   0.000069  -0.072341   -0.084345   -0.066826       0.016297   \n",
       "1570  2194200   0.010196  -0.030095   -0.077565   -0.067667       0.015318   \n",
       "1571  2250800   0.019572   0.006124   -0.068118   -0.046817       0.017313   \n",
       "1572  1741800  -0.029028  -0.026489   -0.096462   -0.079118       0.021824   \n",
       "1573  2225400  -0.003375  -0.003238   -0.092574   -0.084257       0.018301   \n",
       "\n",
       "      Volatility_10d  Volatility_20d      SMA_10      SMA_50     SMA_200  \\\n",
       "1564        0.012413        0.014346  154.043616  153.078423  146.846470   \n",
       "1565        0.017004        0.016179  154.138420  152.949674  146.984801   \n",
       "1566        0.015774        0.016196  153.633244  152.762948  147.118386   \n",
       "1567        0.014128        0.015698  152.903145  152.589342  147.260072   \n",
       "1568        0.015044        0.016531  151.684406  152.395288  147.377151   \n",
       "1569        0.014540        0.016238  150.374692  152.191647  147.476061   \n",
       "1570        0.015356        0.016509  149.166905  151.983153  147.583290   \n",
       "1571        0.016909        0.016119  148.096439  151.839295  147.707401   \n",
       "1572        0.017953        0.016809  146.578369  151.594961  147.799053   \n",
       "1573        0.018064        0.016147  145.132626  151.334181  147.885626   \n",
       "\n",
       "         RSI_14  Volume_Change_5d  Volume_Change_10d  \n",
       "1564  36.814534               1.0                1.0  \n",
       "1565  35.325437               1.0                1.0  \n",
       "1566  33.602793               1.0                1.0  \n",
       "1567  33.329199               1.0                1.0  \n",
       "1568  32.621562               1.0                1.0  \n",
       "1569  27.632004               1.0                1.0  \n",
       "1570  23.688397               1.0                1.0  \n",
       "1571  24.077675               1.0                1.0  \n",
       "1572  22.946890               1.0                1.0  \n",
       "1573  25.566777               1.0                1.0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-rmse:0.02043\n",
      "[1]\ttrain-rmse:0.01996\n",
      "[2]\ttrain-rmse:0.01957\n",
      "[3]\ttrain-rmse:0.01920\n",
      "[4]\ttrain-rmse:0.01893\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jesse/Projects/myenvs/xgboost/lib/python3.12/site-packages/xgboost/callback.py:386: UserWarning: [23:51:59] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  self.starting_round = model.num_boosted_rounds()\n",
      "/home/jesse/Projects/myenvs/xgboost/lib/python3.12/site-packages/xgboost/callback.py:386: UserWarning: [23:51:59] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"n_estimators\", \"predictor\" } are not used.\n",
      "\n",
      "  self.starting_round = model.num_boosted_rounds()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5]\ttrain-rmse:0.01870\n",
      "[6]\ttrain-rmse:0.01846\n",
      "[7]\ttrain-rmse:0.01822\n",
      "[8]\ttrain-rmse:0.01806\n",
      "[9]\ttrain-rmse:0.01787\n",
      "[10]\ttrain-rmse:0.01771\n",
      "[11]\ttrain-rmse:0.01755\n",
      "[12]\ttrain-rmse:0.01744\n",
      "[13]\ttrain-rmse:0.01734\n",
      "[14]\ttrain-rmse:0.01723\n",
      "[15]\ttrain-rmse:0.01712\n",
      "[16]\ttrain-rmse:0.01704\n",
      "[17]\ttrain-rmse:0.01696\n",
      "[18]\ttrain-rmse:0.01690\n",
      "[19]\ttrain-rmse:0.01684\n",
      "[20]\ttrain-rmse:0.01678\n",
      "[21]\ttrain-rmse:0.01670\n",
      "[22]\ttrain-rmse:0.01663\n",
      "[23]\ttrain-rmse:0.01654\n",
      "[24]\ttrain-rmse:0.01650\n",
      "[25]\ttrain-rmse:0.01643\n",
      "[26]\ttrain-rmse:0.01638\n",
      "[27]\ttrain-rmse:0.01634\n",
      "[28]\ttrain-rmse:0.01629\n",
      "[29]\ttrain-rmse:0.01623\n",
      "[30]\ttrain-rmse:0.01619\n",
      "[31]\ttrain-rmse:0.01615\n",
      "[32]\ttrain-rmse:0.01611\n",
      "[33]\ttrain-rmse:0.01605\n",
      "[34]\ttrain-rmse:0.01601\n",
      "[35]\ttrain-rmse:0.01594\n",
      "[36]\ttrain-rmse:0.01592\n",
      "[37]\ttrain-rmse:0.01587\n",
      "[38]\ttrain-rmse:0.01585\n",
      "[39]\ttrain-rmse:0.01582\n",
      "[40]\ttrain-rmse:0.01577\n",
      "[41]\ttrain-rmse:0.01574\n",
      "[42]\ttrain-rmse:0.01569\n",
      "[43]\ttrain-rmse:0.01564\n",
      "[44]\ttrain-rmse:0.01560\n",
      "[45]\ttrain-rmse:0.01557\n",
      "[46]\ttrain-rmse:0.01552\n",
      "[47]\ttrain-rmse:0.01549\n",
      "[48]\ttrain-rmse:0.01546\n",
      "[49]\ttrain-rmse:0.01544\n",
      "[50]\ttrain-rmse:0.01542\n",
      "[51]\ttrain-rmse:0.01538\n",
      "[52]\ttrain-rmse:0.01535\n",
      "[53]\ttrain-rmse:0.01533\n",
      "[54]\ttrain-rmse:0.01530\n",
      "[55]\ttrain-rmse:0.01527\n",
      "[56]\ttrain-rmse:0.01525\n",
      "[57]\ttrain-rmse:0.01520\n",
      "[58]\ttrain-rmse:0.01515\n",
      "[59]\ttrain-rmse:0.01514\n",
      "[60]\ttrain-rmse:0.01513\n",
      "[61]\ttrain-rmse:0.01509\n",
      "[62]\ttrain-rmse:0.01505\n",
      "[63]\ttrain-rmse:0.01502\n",
      "[64]\ttrain-rmse:0.01500\n",
      "[65]\ttrain-rmse:0.01495\n",
      "[66]\ttrain-rmse:0.01488\n",
      "[67]\ttrain-rmse:0.01487\n",
      "[68]\ttrain-rmse:0.01481\n",
      "[69]\ttrain-rmse:0.01480\n",
      "[70]\ttrain-rmse:0.01477\n",
      "[71]\ttrain-rmse:0.01474\n",
      "[72]\ttrain-rmse:0.01471\n",
      "[73]\ttrain-rmse:0.01469\n",
      "[74]\ttrain-rmse:0.01468\n",
      "[75]\ttrain-rmse:0.01465\n",
      "[76]\ttrain-rmse:0.01462\n",
      "[77]\ttrain-rmse:0.01460\n",
      "[78]\ttrain-rmse:0.01456\n",
      "[79]\ttrain-rmse:0.01454\n",
      "[80]\ttrain-rmse:0.01451\n",
      "[81]\ttrain-rmse:0.01450\n",
      "[82]\ttrain-rmse:0.01447\n",
      "[83]\ttrain-rmse:0.01445\n",
      "[84]\ttrain-rmse:0.01443\n",
      "[85]\ttrain-rmse:0.01440\n",
      "[86]\ttrain-rmse:0.01438\n",
      "[87]\ttrain-rmse:0.01435\n",
      "[88]\ttrain-rmse:0.01433\n",
      "[89]\ttrain-rmse:0.01431\n",
      "[90]\ttrain-rmse:0.01428\n",
      "[91]\ttrain-rmse:0.01426\n",
      "[92]\ttrain-rmse:0.01424\n",
      "[93]\ttrain-rmse:0.01422\n",
      "[94]\ttrain-rmse:0.01419\n",
      "[95]\ttrain-rmse:0.01417\n",
      "[96]\ttrain-rmse:0.01414\n",
      "[97]\ttrain-rmse:0.01412\n",
      "[98]\ttrain-rmse:0.01409\n",
      "[99]\ttrain-rmse:0.01408\n",
      "[100]\ttrain-rmse:0.01406\n",
      "[101]\ttrain-rmse:0.01403\n",
      "[102]\ttrain-rmse:0.01401\n",
      "[103]\ttrain-rmse:0.01399\n",
      "[104]\ttrain-rmse:0.01397\n",
      "[105]\ttrain-rmse:0.01394\n",
      "[106]\ttrain-rmse:0.01391\n",
      "[107]\ttrain-rmse:0.01390\n",
      "[108]\ttrain-rmse:0.01389\n",
      "[109]\ttrain-rmse:0.01387\n",
      "[110]\ttrain-rmse:0.01386\n",
      "[111]\ttrain-rmse:0.01384\n",
      "[112]\ttrain-rmse:0.01381\n",
      "[113]\ttrain-rmse:0.01380\n",
      "[114]\ttrain-rmse:0.01379\n",
      "[115]\ttrain-rmse:0.01377\n",
      "[116]\ttrain-rmse:0.01373\n",
      "[117]\ttrain-rmse:0.01372\n",
      "[118]\ttrain-rmse:0.01371\n",
      "[119]\ttrain-rmse:0.01369\n",
      "[120]\ttrain-rmse:0.01367\n",
      "[121]\ttrain-rmse:0.01366\n",
      "[122]\ttrain-rmse:0.01365\n",
      "[123]\ttrain-rmse:0.01363\n",
      "[124]\ttrain-rmse:0.01362\n",
      "[125]\ttrain-rmse:0.01359\n",
      "[126]\ttrain-rmse:0.01358\n",
      "[127]\ttrain-rmse:0.01356\n",
      "[128]\ttrain-rmse:0.01354\n",
      "[129]\ttrain-rmse:0.01351\n",
      "[130]\ttrain-rmse:0.01350\n",
      "[131]\ttrain-rmse:0.01348\n",
      "[132]\ttrain-rmse:0.01347\n",
      "[133]\ttrain-rmse:0.01344\n",
      "[134]\ttrain-rmse:0.01343\n",
      "[135]\ttrain-rmse:0.01341\n",
      "[136]\ttrain-rmse:0.01340\n",
      "[137]\ttrain-rmse:0.01338\n",
      "[138]\ttrain-rmse:0.01335\n",
      "[139]\ttrain-rmse:0.01334\n",
      "[140]\ttrain-rmse:0.01332\n",
      "[141]\ttrain-rmse:0.01330\n",
      "[142]\ttrain-rmse:0.01328\n",
      "[143]\ttrain-rmse:0.01327\n",
      "[144]\ttrain-rmse:0.01323\n",
      "[145]\ttrain-rmse:0.01322\n",
      "[146]\ttrain-rmse:0.01320\n",
      "[147]\ttrain-rmse:0.01319\n",
      "[148]\ttrain-rmse:0.01316\n",
      "[149]\ttrain-rmse:0.01315\n",
      "[150]\ttrain-rmse:0.01314\n",
      "[151]\ttrain-rmse:0.01312\n",
      "[152]\ttrain-rmse:0.01310\n",
      "[153]\ttrain-rmse:0.01308\n",
      "[154]\ttrain-rmse:0.01307\n",
      "[155]\ttrain-rmse:0.01305\n",
      "[156]\ttrain-rmse:0.01303\n",
      "[157]\ttrain-rmse:0.01302\n",
      "[158]\ttrain-rmse:0.01299\n",
      "[159]\ttrain-rmse:0.01298\n",
      "[160]\ttrain-rmse:0.01297\n",
      "[161]\ttrain-rmse:0.01295\n",
      "[162]\ttrain-rmse:0.01293\n",
      "[163]\ttrain-rmse:0.01292\n",
      "[164]\ttrain-rmse:0.01287\n",
      "[165]\ttrain-rmse:0.01285\n",
      "[166]\ttrain-rmse:0.01283\n",
      "[167]\ttrain-rmse:0.01282\n",
      "[168]\ttrain-rmse:0.01281\n",
      "[169]\ttrain-rmse:0.01280\n",
      "[170]\ttrain-rmse:0.01277\n",
      "[171]\ttrain-rmse:0.01276\n",
      "[172]\ttrain-rmse:0.01275\n",
      "[173]\ttrain-rmse:0.01273\n",
      "[174]\ttrain-rmse:0.01272\n",
      "[175]\ttrain-rmse:0.01272\n",
      "[176]\ttrain-rmse:0.01268\n",
      "[177]\ttrain-rmse:0.01267\n",
      "[178]\ttrain-rmse:0.01266\n",
      "[179]\ttrain-rmse:0.01264\n",
      "[180]\ttrain-rmse:0.01261\n",
      "[181]\ttrain-rmse:0.01259\n",
      "[182]\ttrain-rmse:0.01259\n",
      "[183]\ttrain-rmse:0.01257\n",
      "[184]\ttrain-rmse:0.01256\n",
      "[185]\ttrain-rmse:0.01256\n",
      "[186]\ttrain-rmse:0.01255\n",
      "[187]\ttrain-rmse:0.01255\n",
      "[188]\ttrain-rmse:0.01253\n",
      "[189]\ttrain-rmse:0.01251\n",
      "[190]\ttrain-rmse:0.01250\n",
      "[191]\ttrain-rmse:0.01249\n",
      "[192]\ttrain-rmse:0.01248\n",
      "[193]\ttrain-rmse:0.01246\n",
      "[194]\ttrain-rmse:0.01245\n",
      "[195]\ttrain-rmse:0.01244\n",
      "[196]\ttrain-rmse:0.01243\n",
      "[197]\ttrain-rmse:0.01242\n",
      "[198]\ttrain-rmse:0.01240\n",
      "[199]\ttrain-rmse:0.01239\n",
      "[200]\ttrain-rmse:0.01237\n",
      "[201]\ttrain-rmse:0.01235\n",
      "[202]\ttrain-rmse:0.01233\n",
      "[203]\ttrain-rmse:0.01233\n",
      "[204]\ttrain-rmse:0.01232\n",
      "[205]\ttrain-rmse:0.01231\n",
      "[206]\ttrain-rmse:0.01230\n",
      "[207]\ttrain-rmse:0.01226\n",
      "[208]\ttrain-rmse:0.01225\n",
      "[209]\ttrain-rmse:0.01223\n",
      "[210]\ttrain-rmse:0.01222\n",
      "[211]\ttrain-rmse:0.01220\n",
      "[212]\ttrain-rmse:0.01219\n",
      "[213]\ttrain-rmse:0.01217\n",
      "[214]\ttrain-rmse:0.01216\n",
      "[215]\ttrain-rmse:0.01215\n",
      "[216]\ttrain-rmse:0.01214\n",
      "[217]\ttrain-rmse:0.01213\n",
      "[218]\ttrain-rmse:0.01211\n",
      "[219]\ttrain-rmse:0.01210\n",
      "[220]\ttrain-rmse:0.01209\n",
      "[221]\ttrain-rmse:0.01206\n",
      "[222]\ttrain-rmse:0.01204\n",
      "[223]\ttrain-rmse:0.01203\n",
      "[224]\ttrain-rmse:0.01202\n",
      "[225]\ttrain-rmse:0.01199\n",
      "[226]\ttrain-rmse:0.01198\n",
      "[227]\ttrain-rmse:0.01197\n",
      "[228]\ttrain-rmse:0.01195\n",
      "[229]\ttrain-rmse:0.01194\n",
      "[230]\ttrain-rmse:0.01193\n",
      "[231]\ttrain-rmse:0.01193\n",
      "[232]\ttrain-rmse:0.01191\n",
      "[233]\ttrain-rmse:0.01186\n",
      "[234]\ttrain-rmse:0.01186\n",
      "[235]\ttrain-rmse:0.01185\n",
      "[236]\ttrain-rmse:0.01184\n",
      "[237]\ttrain-rmse:0.01183\n",
      "[238]\ttrain-rmse:0.01182\n",
      "[239]\ttrain-rmse:0.01181\n",
      "[240]\ttrain-rmse:0.01180\n",
      "[241]\ttrain-rmse:0.01178\n",
      "[242]\ttrain-rmse:0.01177\n",
      "[243]\ttrain-rmse:0.01176\n",
      "[244]\ttrain-rmse:0.01175\n",
      "[245]\ttrain-rmse:0.01174\n",
      "[246]\ttrain-rmse:0.01173\n",
      "[247]\ttrain-rmse:0.01172\n",
      "[248]\ttrain-rmse:0.01171\n",
      "[249]\ttrain-rmse:0.01170\n",
      "[250]\ttrain-rmse:0.01169\n",
      "[251]\ttrain-rmse:0.01168\n",
      "[252]\ttrain-rmse:0.01166\n",
      "[253]\ttrain-rmse:0.01164\n",
      "[254]\ttrain-rmse:0.01163\n",
      "[255]\ttrain-rmse:0.01162\n",
      "[256]\ttrain-rmse:0.01161\n",
      "[257]\ttrain-rmse:0.01157\n",
      "[258]\ttrain-rmse:0.01156\n",
      "[259]\ttrain-rmse:0.01155\n",
      "[260]\ttrain-rmse:0.01154\n",
      "[261]\ttrain-rmse:0.01154\n",
      "[262]\ttrain-rmse:0.01153\n",
      "[263]\ttrain-rmse:0.01152\n",
      "[264]\ttrain-rmse:0.01151\n",
      "[265]\ttrain-rmse:0.01150\n",
      "[266]\ttrain-rmse:0.01149\n",
      "[267]\ttrain-rmse:0.01148\n",
      "[268]\ttrain-rmse:0.01147\n",
      "[269]\ttrain-rmse:0.01147\n",
      "[270]\ttrain-rmse:0.01145\n",
      "[271]\ttrain-rmse:0.01144\n",
      "[272]\ttrain-rmse:0.01143\n",
      "[273]\ttrain-rmse:0.01142\n",
      "[274]\ttrain-rmse:0.01141\n",
      "[275]\ttrain-rmse:0.01141\n",
      "[276]\ttrain-rmse:0.01140\n",
      "[277]\ttrain-rmse:0.01140\n",
      "[278]\ttrain-rmse:0.01138\n",
      "[279]\ttrain-rmse:0.01137\n",
      "[280]\ttrain-rmse:0.01137\n",
      "[281]\ttrain-rmse:0.01136\n",
      "[282]\ttrain-rmse:0.01134\n",
      "[283]\ttrain-rmse:0.01133\n",
      "[284]\ttrain-rmse:0.01132\n",
      "[285]\ttrain-rmse:0.01131\n",
      "[286]\ttrain-rmse:0.01130\n",
      "[287]\ttrain-rmse:0.01128\n",
      "[288]\ttrain-rmse:0.01128\n",
      "[289]\ttrain-rmse:0.01128\n",
      "[290]\ttrain-rmse:0.01127\n",
      "[291]\ttrain-rmse:0.01127\n",
      "[292]\ttrain-rmse:0.01125\n",
      "[293]\ttrain-rmse:0.01124\n",
      "[294]\ttrain-rmse:0.01124\n",
      "[295]\ttrain-rmse:0.01123\n",
      "[296]\ttrain-rmse:0.01120\n",
      "[297]\ttrain-rmse:0.01120\n",
      "[298]\ttrain-rmse:0.01118\n",
      "[299]\ttrain-rmse:0.01117\n",
      "[300]\ttrain-rmse:0.01117\n",
      "[301]\ttrain-rmse:0.01116\n",
      "[302]\ttrain-rmse:0.01115\n",
      "[303]\ttrain-rmse:0.01114\n",
      "[304]\ttrain-rmse:0.01113\n",
      "[305]\ttrain-rmse:0.01112\n",
      "[306]\ttrain-rmse:0.01110\n",
      "[307]\ttrain-rmse:0.01109\n",
      "[308]\ttrain-rmse:0.01108\n",
      "[309]\ttrain-rmse:0.01107\n",
      "[310]\ttrain-rmse:0.01107\n",
      "[311]\ttrain-rmse:0.01106\n",
      "[312]\ttrain-rmse:0.01105\n",
      "[313]\ttrain-rmse:0.01104\n",
      "[314]\ttrain-rmse:0.01103\n",
      "[315]\ttrain-rmse:0.01103\n",
      "[316]\ttrain-rmse:0.01102\n",
      "[317]\ttrain-rmse:0.01101\n",
      "[318]\ttrain-rmse:0.01100\n",
      "[319]\ttrain-rmse:0.01099\n",
      "[320]\ttrain-rmse:0.01099\n",
      "[321]\ttrain-rmse:0.01098\n",
      "[322]\ttrain-rmse:0.01096\n",
      "[323]\ttrain-rmse:0.01095\n",
      "[324]\ttrain-rmse:0.01095\n",
      "[325]\ttrain-rmse:0.01094\n",
      "[326]\ttrain-rmse:0.01092\n",
      "[327]\ttrain-rmse:0.01091\n",
      "[328]\ttrain-rmse:0.01091\n",
      "[329]\ttrain-rmse:0.01090\n",
      "[330]\ttrain-rmse:0.01090\n",
      "[331]\ttrain-rmse:0.01089\n",
      "[332]\ttrain-rmse:0.01088\n",
      "[333]\ttrain-rmse:0.01088\n",
      "[334]\ttrain-rmse:0.01088\n",
      "[335]\ttrain-rmse:0.01087\n",
      "[336]\ttrain-rmse:0.01087\n",
      "[337]\ttrain-rmse:0.01085\n",
      "[338]\ttrain-rmse:0.01085\n",
      "[339]\ttrain-rmse:0.01085\n",
      "[340]\ttrain-rmse:0.01084\n",
      "[341]\ttrain-rmse:0.01082\n",
      "[342]\ttrain-rmse:0.01082\n",
      "[343]\ttrain-rmse:0.01081\n",
      "[344]\ttrain-rmse:0.01080\n",
      "[345]\ttrain-rmse:0.01080\n",
      "[346]\ttrain-rmse:0.01079\n",
      "[347]\ttrain-rmse:0.01079\n",
      "[348]\ttrain-rmse:0.01078\n",
      "[349]\ttrain-rmse:0.01077\n",
      "[350]\ttrain-rmse:0.01076\n",
      "[351]\ttrain-rmse:0.01075\n",
      "[352]\ttrain-rmse:0.01074\n",
      "[353]\ttrain-rmse:0.01073\n",
      "[354]\ttrain-rmse:0.01072\n",
      "[355]\ttrain-rmse:0.01071\n",
      "[356]\ttrain-rmse:0.01071\n",
      "[357]\ttrain-rmse:0.01070\n",
      "[358]\ttrain-rmse:0.01069\n",
      "[359]\ttrain-rmse:0.01068\n",
      "[360]\ttrain-rmse:0.01067\n",
      "[361]\ttrain-rmse:0.01066\n",
      "[362]\ttrain-rmse:0.01066\n",
      "[363]\ttrain-rmse:0.01065\n",
      "[364]\ttrain-rmse:0.01064\n",
      "[365]\ttrain-rmse:0.01061\n",
      "[366]\ttrain-rmse:0.01061\n",
      "[367]\ttrain-rmse:0.01060\n",
      "[368]\ttrain-rmse:0.01059\n",
      "[369]\ttrain-rmse:0.01058\n",
      "[370]\ttrain-rmse:0.01058\n",
      "[371]\ttrain-rmse:0.01056\n",
      "[372]\ttrain-rmse:0.01056\n",
      "[373]\ttrain-rmse:0.01055\n",
      "[374]\ttrain-rmse:0.01054\n",
      "[375]\ttrain-rmse:0.01054\n",
      "[376]\ttrain-rmse:0.01053\n",
      "[377]\ttrain-rmse:0.01052\n",
      "[378]\ttrain-rmse:0.01052\n",
      "[379]\ttrain-rmse:0.01051\n",
      "[380]\ttrain-rmse:0.01050\n",
      "[381]\ttrain-rmse:0.01050\n",
      "[382]\ttrain-rmse:0.01049\n",
      "[383]\ttrain-rmse:0.01049\n",
      "[384]\ttrain-rmse:0.01048\n",
      "[385]\ttrain-rmse:0.01048\n",
      "[386]\ttrain-rmse:0.01046\n",
      "[387]\ttrain-rmse:0.01046\n",
      "[388]\ttrain-rmse:0.01045\n",
      "[389]\ttrain-rmse:0.01045\n",
      "[390]\ttrain-rmse:0.01044\n",
      "[391]\ttrain-rmse:0.01043\n",
      "[392]\ttrain-rmse:0.01043\n",
      "[393]\ttrain-rmse:0.01042\n",
      "[394]\ttrain-rmse:0.01041\n",
      "[395]\ttrain-rmse:0.01041\n",
      "[396]\ttrain-rmse:0.01040\n",
      "[397]\ttrain-rmse:0.01040\n",
      "[398]\ttrain-rmse:0.01040\n",
      "[399]\ttrain-rmse:0.01039\n",
      "[400]\ttrain-rmse:0.01037\n",
      "[401]\ttrain-rmse:0.01036\n",
      "[402]\ttrain-rmse:0.01036\n",
      "[403]\ttrain-rmse:0.01035\n",
      "[404]\ttrain-rmse:0.01034\n",
      "[405]\ttrain-rmse:0.01034\n",
      "[406]\ttrain-rmse:0.01033\n",
      "[407]\ttrain-rmse:0.01032\n",
      "[408]\ttrain-rmse:0.01031\n",
      "[409]\ttrain-rmse:0.01030\n",
      "[410]\ttrain-rmse:0.01030\n",
      "[411]\ttrain-rmse:0.01029\n",
      "[412]\ttrain-rmse:0.01028\n",
      "[413]\ttrain-rmse:0.01027\n",
      "[414]\ttrain-rmse:0.01027\n",
      "[415]\ttrain-rmse:0.01026\n",
      "[416]\ttrain-rmse:0.01025\n",
      "[417]\ttrain-rmse:0.01025\n",
      "[418]\ttrain-rmse:0.01024\n",
      "[419]\ttrain-rmse:0.01024\n",
      "[420]\ttrain-rmse:0.01023\n",
      "[421]\ttrain-rmse:0.01023\n",
      "[422]\ttrain-rmse:0.01023\n",
      "[423]\ttrain-rmse:0.01021\n",
      "[424]\ttrain-rmse:0.01021\n",
      "[425]\ttrain-rmse:0.01021\n",
      "[426]\ttrain-rmse:0.01020\n",
      "[427]\ttrain-rmse:0.01019\n",
      "[428]\ttrain-rmse:0.01019\n",
      "[429]\ttrain-rmse:0.01018\n",
      "[430]\ttrain-rmse:0.01017\n",
      "[431]\ttrain-rmse:0.01017\n",
      "[432]\ttrain-rmse:0.01016\n",
      "[433]\ttrain-rmse:0.01015\n",
      "[434]\ttrain-rmse:0.01014\n",
      "[435]\ttrain-rmse:0.01013\n",
      "[436]\ttrain-rmse:0.01013\n",
      "[437]\ttrain-rmse:0.01012\n",
      "[438]\ttrain-rmse:0.01011\n",
      "[439]\ttrain-rmse:0.01011\n",
      "[440]\ttrain-rmse:0.01010\n",
      "[441]\ttrain-rmse:0.01010\n",
      "[442]\ttrain-rmse:0.01009\n",
      "[443]\ttrain-rmse:0.01009\n",
      "[444]\ttrain-rmse:0.01009\n",
      "[445]\ttrain-rmse:0.01008\n",
      "[446]\ttrain-rmse:0.01008\n",
      "[447]\ttrain-rmse:0.01007\n",
      "[448]\ttrain-rmse:0.01006\n",
      "[449]\ttrain-rmse:0.01006\n",
      "[450]\ttrain-rmse:0.01005\n",
      "[451]\ttrain-rmse:0.01004\n",
      "[452]\ttrain-rmse:0.01004\n",
      "[453]\ttrain-rmse:0.01003\n",
      "[454]\ttrain-rmse:0.01003\n",
      "[455]\ttrain-rmse:0.01002\n",
      "[456]\ttrain-rmse:0.01001\n",
      "[457]\ttrain-rmse:0.01000\n",
      "[458]\ttrain-rmse:0.01000\n",
      "[459]\ttrain-rmse:0.01000\n",
      "[460]\ttrain-rmse:0.00999\n",
      "[461]\ttrain-rmse:0.00999\n",
      "[462]\ttrain-rmse:0.00998\n",
      "[463]\ttrain-rmse:0.00997\n",
      "[464]\ttrain-rmse:0.00997\n",
      "[465]\ttrain-rmse:0.00996\n",
      "[466]\ttrain-rmse:0.00996\n",
      "[467]\ttrain-rmse:0.00995\n",
      "[468]\ttrain-rmse:0.00995\n",
      "[469]\ttrain-rmse:0.00994\n",
      "[470]\ttrain-rmse:0.00994\n",
      "[471]\ttrain-rmse:0.00994\n",
      "[472]\ttrain-rmse:0.00993\n",
      "[473]\ttrain-rmse:0.00992\n",
      "[474]\ttrain-rmse:0.00992\n",
      "[475]\ttrain-rmse:0.00991\n",
      "[476]\ttrain-rmse:0.00991\n",
      "[477]\ttrain-rmse:0.00990\n",
      "[478]\ttrain-rmse:0.00989\n",
      "[479]\ttrain-rmse:0.00987\n",
      "[480]\ttrain-rmse:0.00987\n",
      "[481]\ttrain-rmse:0.00986\n",
      "[482]\ttrain-rmse:0.00986\n",
      "[483]\ttrain-rmse:0.00985\n",
      "[484]\ttrain-rmse:0.00984\n",
      "[485]\ttrain-rmse:0.00984\n",
      "[486]\ttrain-rmse:0.00983\n",
      "[487]\ttrain-rmse:0.00982\n",
      "[488]\ttrain-rmse:0.00982\n",
      "[489]\ttrain-rmse:0.00981\n",
      "[490]\ttrain-rmse:0.00980\n",
      "[491]\ttrain-rmse:0.00980\n",
      "[492]\ttrain-rmse:0.00979\n",
      "[493]\ttrain-rmse:0.00978\n",
      "[494]\ttrain-rmse:0.00978\n",
      "[495]\ttrain-rmse:0.00977\n",
      "[496]\ttrain-rmse:0.00976\n",
      "[497]\ttrain-rmse:0.00975\n",
      "[498]\ttrain-rmse:0.00974\n",
      "[499]\ttrain-rmse:0.00974\n",
      "[500]\ttrain-rmse:0.00974\n",
      "[501]\ttrain-rmse:0.00973\n",
      "[502]\ttrain-rmse:0.00972\n",
      "[503]\ttrain-rmse:0.00972\n",
      "[504]\ttrain-rmse:0.00971\n",
      "[505]\ttrain-rmse:0.00970\n",
      "[506]\ttrain-rmse:0.00969\n",
      "[507]\ttrain-rmse:0.00968\n",
      "[508]\ttrain-rmse:0.00967\n",
      "[509]\ttrain-rmse:0.00966\n",
      "[510]\ttrain-rmse:0.00966\n",
      "[511]\ttrain-rmse:0.00965\n",
      "[512]\ttrain-rmse:0.00964\n",
      "[513]\ttrain-rmse:0.00964\n",
      "[514]\ttrain-rmse:0.00963\n",
      "[515]\ttrain-rmse:0.00962\n",
      "[516]\ttrain-rmse:0.00962\n",
      "[517]\ttrain-rmse:0.00961\n",
      "[518]\ttrain-rmse:0.00961\n",
      "[519]\ttrain-rmse:0.00961\n",
      "[520]\ttrain-rmse:0.00960\n",
      "[521]\ttrain-rmse:0.00960\n",
      "[522]\ttrain-rmse:0.00960\n",
      "[523]\ttrain-rmse:0.00959\n",
      "[524]\ttrain-rmse:0.00959\n",
      "[525]\ttrain-rmse:0.00959\n",
      "[526]\ttrain-rmse:0.00958\n",
      "[527]\ttrain-rmse:0.00958\n",
      "[528]\ttrain-rmse:0.00957\n",
      "[529]\ttrain-rmse:0.00954\n",
      "[530]\ttrain-rmse:0.00954\n",
      "[531]\ttrain-rmse:0.00953\n",
      "[532]\ttrain-rmse:0.00953\n",
      "[533]\ttrain-rmse:0.00952\n",
      "[534]\ttrain-rmse:0.00952\n",
      "[535]\ttrain-rmse:0.00951\n",
      "[536]\ttrain-rmse:0.00951\n",
      "[537]\ttrain-rmse:0.00947\n",
      "[538]\ttrain-rmse:0.00947\n",
      "[539]\ttrain-rmse:0.00946\n",
      "[540]\ttrain-rmse:0.00946\n",
      "[541]\ttrain-rmse:0.00945\n",
      "[542]\ttrain-rmse:0.00945\n",
      "[543]\ttrain-rmse:0.00944\n",
      "[544]\ttrain-rmse:0.00944\n",
      "[545]\ttrain-rmse:0.00943\n",
      "[546]\ttrain-rmse:0.00943\n",
      "[547]\ttrain-rmse:0.00942\n",
      "[548]\ttrain-rmse:0.00942\n",
      "[549]\ttrain-rmse:0.00942\n",
      "[550]\ttrain-rmse:0.00941\n",
      "[551]\ttrain-rmse:0.00941\n",
      "[552]\ttrain-rmse:0.00940\n",
      "[553]\ttrain-rmse:0.00940\n",
      "[554]\ttrain-rmse:0.00939\n",
      "[555]\ttrain-rmse:0.00939\n",
      "[556]\ttrain-rmse:0.00939\n",
      "[557]\ttrain-rmse:0.00938\n",
      "[558]\ttrain-rmse:0.00938\n",
      "[559]\ttrain-rmse:0.00938\n",
      "[560]\ttrain-rmse:0.00938\n",
      "[561]\ttrain-rmse:0.00937\n",
      "[562]\ttrain-rmse:0.00937\n",
      "[563]\ttrain-rmse:0.00936\n",
      "[564]\ttrain-rmse:0.00936\n",
      "[565]\ttrain-rmse:0.00935\n",
      "[566]\ttrain-rmse:0.00934\n",
      "[567]\ttrain-rmse:0.00934\n",
      "[568]\ttrain-rmse:0.00933\n",
      "[569]\ttrain-rmse:0.00933\n",
      "[570]\ttrain-rmse:0.00932\n",
      "[571]\ttrain-rmse:0.00932\n",
      "[572]\ttrain-rmse:0.00932\n",
      "[573]\ttrain-rmse:0.00931\n",
      "[574]\ttrain-rmse:0.00931\n",
      "[575]\ttrain-rmse:0.00930\n",
      "[576]\ttrain-rmse:0.00930\n",
      "[577]\ttrain-rmse:0.00929\n",
      "[578]\ttrain-rmse:0.00928\n",
      "[579]\ttrain-rmse:0.00927\n",
      "[580]\ttrain-rmse:0.00926\n",
      "[581]\ttrain-rmse:0.00926\n",
      "[582]\ttrain-rmse:0.00926\n",
      "[583]\ttrain-rmse:0.00925\n",
      "[584]\ttrain-rmse:0.00925\n",
      "[585]\ttrain-rmse:0.00925\n",
      "[586]\ttrain-rmse:0.00924\n",
      "[587]\ttrain-rmse:0.00924\n",
      "[588]\ttrain-rmse:0.00923\n",
      "[589]\ttrain-rmse:0.00923\n",
      "[590]\ttrain-rmse:0.00922\n",
      "[591]\ttrain-rmse:0.00922\n",
      "[592]\ttrain-rmse:0.00921\n",
      "[593]\ttrain-rmse:0.00920\n",
      "[594]\ttrain-rmse:0.00920\n",
      "[595]\ttrain-rmse:0.00920\n",
      "[596]\ttrain-rmse:0.00919\n",
      "[597]\ttrain-rmse:0.00917\n",
      "[598]\ttrain-rmse:0.00917\n",
      "[599]\ttrain-rmse:0.00916\n",
      "[600]\ttrain-rmse:0.00916\n",
      "[601]\ttrain-rmse:0.00915\n",
      "[602]\ttrain-rmse:0.00915\n",
      "[603]\ttrain-rmse:0.00915\n",
      "[604]\ttrain-rmse:0.00914\n",
      "[605]\ttrain-rmse:0.00914\n",
      "[606]\ttrain-rmse:0.00913\n",
      "[607]\ttrain-rmse:0.00913\n",
      "[608]\ttrain-rmse:0.00912\n",
      "[609]\ttrain-rmse:0.00912\n",
      "[610]\ttrain-rmse:0.00911\n",
      "[611]\ttrain-rmse:0.00911\n",
      "[612]\ttrain-rmse:0.00911\n",
      "[613]\ttrain-rmse:0.00910\n",
      "[614]\ttrain-rmse:0.00909\n",
      "[615]\ttrain-rmse:0.00909\n",
      "[616]\ttrain-rmse:0.00909\n",
      "[617]\ttrain-rmse:0.00908\n",
      "[618]\ttrain-rmse:0.00908\n",
      "[619]\ttrain-rmse:0.00908\n",
      "[620]\ttrain-rmse:0.00907\n",
      "[621]\ttrain-rmse:0.00906\n",
      "[622]\ttrain-rmse:0.00906\n",
      "[623]\ttrain-rmse:0.00906\n",
      "[624]\ttrain-rmse:0.00906\n",
      "[625]\ttrain-rmse:0.00905\n",
      "[626]\ttrain-rmse:0.00904\n",
      "[627]\ttrain-rmse:0.00904\n",
      "[628]\ttrain-rmse:0.00903\n",
      "[629]\ttrain-rmse:0.00902\n",
      "[630]\ttrain-rmse:0.00902\n",
      "[631]\ttrain-rmse:0.00901\n",
      "[632]\ttrain-rmse:0.00900\n",
      "[633]\ttrain-rmse:0.00900\n",
      "[634]\ttrain-rmse:0.00899\n",
      "[635]\ttrain-rmse:0.00899\n",
      "[636]\ttrain-rmse:0.00899\n",
      "[637]\ttrain-rmse:0.00898\n",
      "[638]\ttrain-rmse:0.00898\n",
      "[639]\ttrain-rmse:0.00897\n",
      "[640]\ttrain-rmse:0.00897\n",
      "[641]\ttrain-rmse:0.00897\n",
      "[642]\ttrain-rmse:0.00897\n",
      "[643]\ttrain-rmse:0.00896\n",
      "[644]\ttrain-rmse:0.00896\n",
      "[645]\ttrain-rmse:0.00895\n",
      "[646]\ttrain-rmse:0.00895\n",
      "[647]\ttrain-rmse:0.00895\n",
      "[648]\ttrain-rmse:0.00894\n",
      "[649]\ttrain-rmse:0.00894\n",
      "[650]\ttrain-rmse:0.00893\n",
      "[651]\ttrain-rmse:0.00892\n",
      "[652]\ttrain-rmse:0.00892\n",
      "[653]\ttrain-rmse:0.00891\n",
      "[654]\ttrain-rmse:0.00891\n",
      "[655]\ttrain-rmse:0.00890\n",
      "[656]\ttrain-rmse:0.00890\n",
      "[657]\ttrain-rmse:0.00889\n",
      "[658]\ttrain-rmse:0.00889\n",
      "[659]\ttrain-rmse:0.00888\n",
      "[660]\ttrain-rmse:0.00888\n",
      "[661]\ttrain-rmse:0.00888\n",
      "[662]\ttrain-rmse:0.00887\n",
      "[663]\ttrain-rmse:0.00887\n",
      "[664]\ttrain-rmse:0.00886\n",
      "[665]\ttrain-rmse:0.00886\n",
      "[666]\ttrain-rmse:0.00886\n",
      "[667]\ttrain-rmse:0.00883\n",
      "[668]\ttrain-rmse:0.00882\n",
      "[669]\ttrain-rmse:0.00882\n",
      "[670]\ttrain-rmse:0.00882\n",
      "[671]\ttrain-rmse:0.00881\n",
      "[672]\ttrain-rmse:0.00881\n",
      "[673]\ttrain-rmse:0.00881\n",
      "[674]\ttrain-rmse:0.00880\n",
      "[675]\ttrain-rmse:0.00880\n",
      "[676]\ttrain-rmse:0.00879\n",
      "[677]\ttrain-rmse:0.00879\n",
      "[678]\ttrain-rmse:0.00879\n",
      "[679]\ttrain-rmse:0.00878\n",
      "[680]\ttrain-rmse:0.00878\n",
      "[681]\ttrain-rmse:0.00878\n",
      "[682]\ttrain-rmse:0.00877\n",
      "[683]\ttrain-rmse:0.00877\n",
      "[684]\ttrain-rmse:0.00876\n",
      "[685]\ttrain-rmse:0.00876\n",
      "[686]\ttrain-rmse:0.00876\n",
      "[687]\ttrain-rmse:0.00875\n",
      "[688]\ttrain-rmse:0.00875\n",
      "[689]\ttrain-rmse:0.00874\n",
      "[690]\ttrain-rmse:0.00874\n",
      "[691]\ttrain-rmse:0.00873\n",
      "[692]\ttrain-rmse:0.00873\n",
      "[693]\ttrain-rmse:0.00872\n",
      "[694]\ttrain-rmse:0.00872\n",
      "[695]\ttrain-rmse:0.00871\n",
      "[696]\ttrain-rmse:0.00871\n",
      "[697]\ttrain-rmse:0.00870\n",
      "[698]\ttrain-rmse:0.00870\n",
      "[699]\ttrain-rmse:0.00870\n",
      "[700]\ttrain-rmse:0.00868\n",
      "[701]\ttrain-rmse:0.00867\n",
      "[702]\ttrain-rmse:0.00867\n",
      "[703]\ttrain-rmse:0.00867\n",
      "[704]\ttrain-rmse:0.00867\n",
      "[705]\ttrain-rmse:0.00866\n",
      "[706]\ttrain-rmse:0.00866\n",
      "[707]\ttrain-rmse:0.00865\n",
      "[708]\ttrain-rmse:0.00865\n",
      "[709]\ttrain-rmse:0.00865\n",
      "[710]\ttrain-rmse:0.00865\n",
      "[711]\ttrain-rmse:0.00864\n",
      "[712]\ttrain-rmse:0.00863\n",
      "[713]\ttrain-rmse:0.00863\n",
      "[714]\ttrain-rmse:0.00863\n",
      "[715]\ttrain-rmse:0.00862\n",
      "[716]\ttrain-rmse:0.00862\n",
      "[717]\ttrain-rmse:0.00862\n",
      "[718]\ttrain-rmse:0.00861\n",
      "[719]\ttrain-rmse:0.00861\n",
      "[720]\ttrain-rmse:0.00860\n",
      "[721]\ttrain-rmse:0.00859\n",
      "[722]\ttrain-rmse:0.00858\n",
      "[723]\ttrain-rmse:0.00858\n",
      "[724]\ttrain-rmse:0.00858\n",
      "[725]\ttrain-rmse:0.00857\n",
      "[726]\ttrain-rmse:0.00857\n",
      "[727]\ttrain-rmse:0.00857\n",
      "[728]\ttrain-rmse:0.00856\n",
      "[729]\ttrain-rmse:0.00856\n",
      "[730]\ttrain-rmse:0.00856\n",
      "[731]\ttrain-rmse:0.00856\n",
      "[732]\ttrain-rmse:0.00855\n",
      "[733]\ttrain-rmse:0.00855\n",
      "[734]\ttrain-rmse:0.00854\n",
      "[735]\ttrain-rmse:0.00854\n",
      "[736]\ttrain-rmse:0.00854\n",
      "[737]\ttrain-rmse:0.00854\n",
      "[738]\ttrain-rmse:0.00853\n",
      "[739]\ttrain-rmse:0.00853\n",
      "[740]\ttrain-rmse:0.00853\n",
      "[741]\ttrain-rmse:0.00852\n",
      "[742]\ttrain-rmse:0.00852\n",
      "[743]\ttrain-rmse:0.00852\n",
      "[744]\ttrain-rmse:0.00851\n",
      "[745]\ttrain-rmse:0.00851\n",
      "[746]\ttrain-rmse:0.00851\n",
      "[747]\ttrain-rmse:0.00850\n",
      "[748]\ttrain-rmse:0.00850\n",
      "[749]\ttrain-rmse:0.00850\n",
      "[750]\ttrain-rmse:0.00849\n",
      "[751]\ttrain-rmse:0.00849\n",
      "[752]\ttrain-rmse:0.00849\n",
      "[753]\ttrain-rmse:0.00848\n",
      "[754]\ttrain-rmse:0.00848\n",
      "[755]\ttrain-rmse:0.00848\n",
      "[756]\ttrain-rmse:0.00847\n",
      "[757]\ttrain-rmse:0.00847\n",
      "[758]\ttrain-rmse:0.00846\n",
      "[759]\ttrain-rmse:0.00845\n",
      "[760]\ttrain-rmse:0.00845\n",
      "[761]\ttrain-rmse:0.00845\n",
      "[762]\ttrain-rmse:0.00844\n",
      "[763]\ttrain-rmse:0.00843\n",
      "[764]\ttrain-rmse:0.00843\n",
      "[765]\ttrain-rmse:0.00843\n",
      "[766]\ttrain-rmse:0.00842\n",
      "[767]\ttrain-rmse:0.00842\n",
      "[768]\ttrain-rmse:0.00842\n",
      "[769]\ttrain-rmse:0.00841\n",
      "[770]\ttrain-rmse:0.00840\n",
      "[771]\ttrain-rmse:0.00840\n",
      "[772]\ttrain-rmse:0.00839\n",
      "[773]\ttrain-rmse:0.00839\n",
      "[774]\ttrain-rmse:0.00839\n",
      "[775]\ttrain-rmse:0.00838\n",
      "[776]\ttrain-rmse:0.00838\n",
      "[777]\ttrain-rmse:0.00838\n",
      "[778]\ttrain-rmse:0.00838\n",
      "[779]\ttrain-rmse:0.00837\n",
      "[780]\ttrain-rmse:0.00836\n",
      "[781]\ttrain-rmse:0.00836\n",
      "[782]\ttrain-rmse:0.00836\n",
      "[783]\ttrain-rmse:0.00836\n",
      "[784]\ttrain-rmse:0.00836\n",
      "[785]\ttrain-rmse:0.00835\n",
      "[786]\ttrain-rmse:0.00835\n",
      "[787]\ttrain-rmse:0.00835\n",
      "[788]\ttrain-rmse:0.00834\n",
      "[789]\ttrain-rmse:0.00834\n",
      "[790]\ttrain-rmse:0.00833\n",
      "[791]\ttrain-rmse:0.00833\n",
      "[792]\ttrain-rmse:0.00833\n",
      "[793]\ttrain-rmse:0.00832\n",
      "[794]\ttrain-rmse:0.00832\n",
      "[795]\ttrain-rmse:0.00832\n",
      "[796]\ttrain-rmse:0.00832\n",
      "[797]\ttrain-rmse:0.00831\n",
      "[798]\ttrain-rmse:0.00831\n",
      "[799]\ttrain-rmse:0.00830\n",
      "[800]\ttrain-rmse:0.00830\n",
      "[801]\ttrain-rmse:0.00830\n",
      "[802]\ttrain-rmse:0.00830\n",
      "[803]\ttrain-rmse:0.00829\n",
      "[804]\ttrain-rmse:0.00829\n",
      "[805]\ttrain-rmse:0.00828\n",
      "[806]\ttrain-rmse:0.00828\n",
      "[807]\ttrain-rmse:0.00828\n",
      "[808]\ttrain-rmse:0.00828\n",
      "[809]\ttrain-rmse:0.00827\n",
      "[810]\ttrain-rmse:0.00827\n",
      "[811]\ttrain-rmse:0.00826\n",
      "[812]\ttrain-rmse:0.00826\n",
      "[813]\ttrain-rmse:0.00826\n",
      "[814]\ttrain-rmse:0.00825\n",
      "[815]\ttrain-rmse:0.00825\n",
      "[816]\ttrain-rmse:0.00824\n",
      "[817]\ttrain-rmse:0.00824\n",
      "[818]\ttrain-rmse:0.00824\n",
      "[819]\ttrain-rmse:0.00823\n",
      "[820]\ttrain-rmse:0.00823\n",
      "[821]\ttrain-rmse:0.00822\n",
      "[822]\ttrain-rmse:0.00822\n",
      "[823]\ttrain-rmse:0.00822\n",
      "[824]\ttrain-rmse:0.00822\n",
      "[825]\ttrain-rmse:0.00821\n",
      "[826]\ttrain-rmse:0.00821\n",
      "[827]\ttrain-rmse:0.00821\n",
      "[828]\ttrain-rmse:0.00821\n",
      "[829]\ttrain-rmse:0.00820\n",
      "[830]\ttrain-rmse:0.00820\n",
      "[831]\ttrain-rmse:0.00820\n",
      "[832]\ttrain-rmse:0.00819\n",
      "[833]\ttrain-rmse:0.00819\n",
      "[834]\ttrain-rmse:0.00819\n",
      "[835]\ttrain-rmse:0.00818\n",
      "[836]\ttrain-rmse:0.00818\n",
      "[837]\ttrain-rmse:0.00818\n",
      "[838]\ttrain-rmse:0.00817\n",
      "[839]\ttrain-rmse:0.00817\n",
      "[840]\ttrain-rmse:0.00816\n",
      "[841]\ttrain-rmse:0.00816\n",
      "[842]\ttrain-rmse:0.00815\n",
      "[843]\ttrain-rmse:0.00815\n",
      "[844]\ttrain-rmse:0.00814\n",
      "[845]\ttrain-rmse:0.00814\n",
      "[846]\ttrain-rmse:0.00814\n",
      "[847]\ttrain-rmse:0.00813\n",
      "[848]\ttrain-rmse:0.00813\n",
      "[849]\ttrain-rmse:0.00812\n",
      "[850]\ttrain-rmse:0.00812\n",
      "[851]\ttrain-rmse:0.00812\n",
      "[852]\ttrain-rmse:0.00811\n",
      "[853]\ttrain-rmse:0.00811\n",
      "[854]\ttrain-rmse:0.00811\n",
      "[855]\ttrain-rmse:0.00810\n",
      "[856]\ttrain-rmse:0.00810\n",
      "[857]\ttrain-rmse:0.00810\n",
      "[858]\ttrain-rmse:0.00809\n",
      "[859]\ttrain-rmse:0.00809\n",
      "[860]\ttrain-rmse:0.00809\n",
      "[861]\ttrain-rmse:0.00808\n",
      "[862]\ttrain-rmse:0.00808\n",
      "[863]\ttrain-rmse:0.00808\n",
      "[864]\ttrain-rmse:0.00807\n",
      "[865]\ttrain-rmse:0.00807\n",
      "[866]\ttrain-rmse:0.00807\n",
      "[867]\ttrain-rmse:0.00806\n",
      "[868]\ttrain-rmse:0.00806\n",
      "[869]\ttrain-rmse:0.00806\n",
      "[870]\ttrain-rmse:0.00806\n",
      "[871]\ttrain-rmse:0.00805\n",
      "[872]\ttrain-rmse:0.00805\n",
      "[873]\ttrain-rmse:0.00805\n",
      "[874]\ttrain-rmse:0.00804\n",
      "[875]\ttrain-rmse:0.00804\n",
      "[876]\ttrain-rmse:0.00804\n",
      "[877]\ttrain-rmse:0.00804\n",
      "[878]\ttrain-rmse:0.00803\n",
      "[879]\ttrain-rmse:0.00803\n",
      "[880]\ttrain-rmse:0.00803\n",
      "[881]\ttrain-rmse:0.00803\n",
      "[882]\ttrain-rmse:0.00803\n",
      "[883]\ttrain-rmse:0.00802\n",
      "[884]\ttrain-rmse:0.00802\n",
      "[885]\ttrain-rmse:0.00801\n",
      "[886]\ttrain-rmse:0.00801\n",
      "[887]\ttrain-rmse:0.00801\n",
      "[888]\ttrain-rmse:0.00801\n",
      "[889]\ttrain-rmse:0.00801\n",
      "[890]\ttrain-rmse:0.00800\n",
      "[891]\ttrain-rmse:0.00800\n",
      "[892]\ttrain-rmse:0.00799\n",
      "[893]\ttrain-rmse:0.00799\n",
      "[894]\ttrain-rmse:0.00799\n",
      "[895]\ttrain-rmse:0.00799\n",
      "[896]\ttrain-rmse:0.00798\n",
      "[897]\ttrain-rmse:0.00798\n",
      "[898]\ttrain-rmse:0.00798\n",
      "[899]\ttrain-rmse:0.00797\n",
      "[900]\ttrain-rmse:0.00797\n",
      "[901]\ttrain-rmse:0.00797\n",
      "[902]\ttrain-rmse:0.00796\n",
      "[903]\ttrain-rmse:0.00796\n",
      "[904]\ttrain-rmse:0.00796\n",
      "[905]\ttrain-rmse:0.00795\n",
      "[906]\ttrain-rmse:0.00795\n",
      "[907]\ttrain-rmse:0.00795\n",
      "[908]\ttrain-rmse:0.00794\n",
      "[909]\ttrain-rmse:0.00794\n",
      "[910]\ttrain-rmse:0.00794\n",
      "[911]\ttrain-rmse:0.00793\n",
      "[912]\ttrain-rmse:0.00792\n",
      "[913]\ttrain-rmse:0.00792\n",
      "[914]\ttrain-rmse:0.00791\n",
      "[915]\ttrain-rmse:0.00791\n",
      "[916]\ttrain-rmse:0.00791\n",
      "[917]\ttrain-rmse:0.00790\n",
      "[918]\ttrain-rmse:0.00790\n",
      "[919]\ttrain-rmse:0.00790\n",
      "[920]\ttrain-rmse:0.00789\n",
      "[921]\ttrain-rmse:0.00789\n",
      "[922]\ttrain-rmse:0.00788\n",
      "[923]\ttrain-rmse:0.00788\n",
      "[924]\ttrain-rmse:0.00788\n",
      "[925]\ttrain-rmse:0.00788\n",
      "[926]\ttrain-rmse:0.00787\n",
      "[927]\ttrain-rmse:0.00787\n",
      "[928]\ttrain-rmse:0.00787\n",
      "[929]\ttrain-rmse:0.00785\n",
      "[930]\ttrain-rmse:0.00785\n",
      "[931]\ttrain-rmse:0.00784\n",
      "[932]\ttrain-rmse:0.00784\n",
      "[933]\ttrain-rmse:0.00784\n",
      "[934]\ttrain-rmse:0.00784\n",
      "[935]\ttrain-rmse:0.00782\n",
      "[936]\ttrain-rmse:0.00782\n",
      "[937]\ttrain-rmse:0.00782\n",
      "[938]\ttrain-rmse:0.00782\n",
      "[939]\ttrain-rmse:0.00780\n",
      "[940]\ttrain-rmse:0.00780\n",
      "[941]\ttrain-rmse:0.00780\n",
      "[942]\ttrain-rmse:0.00780\n",
      "[943]\ttrain-rmse:0.00779\n",
      "[944]\ttrain-rmse:0.00779\n",
      "[945]\ttrain-rmse:0.00779\n",
      "[946]\ttrain-rmse:0.00778\n",
      "[947]\ttrain-rmse:0.00778\n",
      "[948]\ttrain-rmse:0.00778\n",
      "[949]\ttrain-rmse:0.00778\n",
      "[950]\ttrain-rmse:0.00777\n",
      "[951]\ttrain-rmse:0.00777\n",
      "[952]\ttrain-rmse:0.00777\n",
      "[953]\ttrain-rmse:0.00776\n",
      "[954]\ttrain-rmse:0.00776\n",
      "[955]\ttrain-rmse:0.00776\n",
      "[956]\ttrain-rmse:0.00775\n",
      "[957]\ttrain-rmse:0.00775\n",
      "[958]\ttrain-rmse:0.00775\n",
      "[959]\ttrain-rmse:0.00774\n",
      "[960]\ttrain-rmse:0.00774\n",
      "[961]\ttrain-rmse:0.00774\n",
      "[962]\ttrain-rmse:0.00773\n",
      "[963]\ttrain-rmse:0.00773\n",
      "[964]\ttrain-rmse:0.00772\n",
      "[965]\ttrain-rmse:0.00772\n",
      "[966]\ttrain-rmse:0.00772\n",
      "[967]\ttrain-rmse:0.00772\n",
      "[968]\ttrain-rmse:0.00772\n",
      "[969]\ttrain-rmse:0.00771\n",
      "[970]\ttrain-rmse:0.00771\n",
      "[971]\ttrain-rmse:0.00771\n",
      "[972]\ttrain-rmse:0.00771\n",
      "[973]\ttrain-rmse:0.00770\n",
      "[974]\ttrain-rmse:0.00770\n",
      "[975]\ttrain-rmse:0.00769\n",
      "[976]\ttrain-rmse:0.00769\n",
      "[977]\ttrain-rmse:0.00769\n",
      "[978]\ttrain-rmse:0.00769\n",
      "[979]\ttrain-rmse:0.00768\n",
      "[980]\ttrain-rmse:0.00768\n",
      "[981]\ttrain-rmse:0.00768\n",
      "[982]\ttrain-rmse:0.00768\n",
      "[983]\ttrain-rmse:0.00767\n",
      "[984]\ttrain-rmse:0.00767\n",
      "[985]\ttrain-rmse:0.00766\n",
      "[986]\ttrain-rmse:0.00766\n",
      "[987]\ttrain-rmse:0.00766\n",
      "[988]\ttrain-rmse:0.00766\n",
      "[989]\ttrain-rmse:0.00765\n",
      "[990]\ttrain-rmse:0.00765\n",
      "[991]\ttrain-rmse:0.00765\n",
      "[992]\ttrain-rmse:0.00765\n",
      "[993]\ttrain-rmse:0.00765\n",
      "[994]\ttrain-rmse:0.00764\n",
      "[995]\ttrain-rmse:0.00764\n",
      "[996]\ttrain-rmse:0.00764\n",
      "[997]\ttrain-rmse:0.00763\n",
      "[998]\ttrain-rmse:0.00763\n",
      "[999]\ttrain-rmse:0.00763\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_48246/521590211.py:44: UserWarning: [23:52:25] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  model.save_model(model_path)\n",
      "/tmp/ipykernel_48246/521590211.py:44: UserWarning: [23:52:25] WARNING: /workspace/src/c_api/c_api.cc:1427: Saving model in the UBJSON format as default.  You can use file extension: `json`, `ubj` or `deprecated` to choose between formats.\n",
      "  model.save_model(model_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model trained successfully and saved at /home/jesse/Projects/CWP_RL/03_XGBoost_Return_Prediction/xgboost_model.bin\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Assuming 'training_df' is your dataframe\n",
    "# Split the data into X (features) and y (target: 1-day return)\n",
    "X_train = train_df.drop(columns=[\"Date\", \"Stock_ID\", \"Return_1d\"])  # Drop non-feature columns\n",
    "y_train = train_df[\"Return_1d\"]\n",
    "\n",
    "# Convert DataFrame to DMatrix for XGBoost (faster training)\n",
    "train_dmatrix = xgb.DMatrix(X_train, label=y_train)\n",
    "\n",
    "\n",
    "# Set up hyperparameters\n",
    "params = {\n",
    "    'learning_rate': 0.1,  # Learning rate\n",
    "    'n_estimators': 1000,  # Number of trees\n",
    "    'max_depth': 12,  # Max depth of trees\n",
    "    'min_child_weight': 1,  # Minimum child weight\n",
    "    'gamma': 0,  # No regularization\n",
    "    'subsample': 0.8,  # Subsample ratio\n",
    "    'colsample_bytree': 0.8,  # Column sample ratio\n",
    "    'lambda': 0,  # L2 regularization\n",
    "    'alpha': 0,  # L1 regularization\n",
    "    'objective': 'reg:squarederror',  # Regression problem\n",
    "    'booster': 'gbtree',  # Use tree-based booster\n",
    "    'eval_metric': 'rmse',  # Evaluation metric: RMSE\n",
    "    'tree_method': 'gpu_hist',  # Use GPU for training\n",
    "    'predictor': 'gpu_predictor'  # Use GPU for prediction\n",
    "}\n",
    "\n",
    "# Train the model with the parameters\n",
    "model = xgb.train(\n",
    "    params=params, \n",
    "    dtrain=train_dmatrix, \n",
    "    num_boost_round=1000,  # Number of boosting rounds\n",
    "    evals=[(train_dmatrix, 'train')],  # Evaluate on training set (you can add validation set here)\n",
    "    early_stopping_rounds=50  # Stop training if no improvement after 50 rounds\n",
    ")\n",
    "\n",
    "# Save the trained model\n",
    "model_path = '/home/jesse/Projects/CWP_RL/03_XGBoost_Return_Prediction/xgboost_model.bin'\n",
    "model.save_model(model_path)\n",
    "\n",
    "print(f\"Model trained successfully and saved at {model_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for infinite values in X_train\n",
    "print(X_train.isin([np.inf, -np.inf]).sum())\n",
    "\n",
    "# Check for values that are too large (e.g., larger than a specific threshold)\n",
    "print((X_train > 1e10).sum())  # Replace 1e10 with a threshold that fits your case\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing or infinite values in the features\n",
    "print(X_train.isna().sum())  # Check for missing values\n",
    "print(np.isinf(X_train).sum())  # Check for infinite values\n",
    "\n",
    "# Check for missing or infinite values in the target\n",
    "print(y_train.isna().sum())  # Check for missing values\n",
    "print(np.isinf(y_train).sum())  # Check for infinite values\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xgboost",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
