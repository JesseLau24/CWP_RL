{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Create a directory to store S&P 500 stock data\n",
    "directory = \"SP500_05_25\"\n",
    "if not os.path.exists(directory):\n",
    "    os.makedirs(directory)\n",
    "\n",
    "# Retrieve the list of S&P 500 stocks from Wikipedia\n",
    "sp500_url = \"https://en.wikipedia.org/wiki/List_of_S%26P_500_companies\"\n",
    "table = pd.read_html(sp500_url)[0]\n",
    "tickers = table['Symbol'].tolist()\n",
    "\n",
    "# Fetch stock data and save as CSV\n",
    "for ticker in tickers:\n",
    "    print(f\"Fetching data for: {ticker}\")\n",
    "    stock_data = yf.download(ticker, start=\"2005-01-01\", end=\"2025-03-25\")\n",
    "    \n",
    "    # Check if the number of data points is less than 100 days\n",
    "    if len(stock_data) < 100:\n",
    "        print(f\"Skipping {ticker}, insufficient data: {len(stock_data)} days\")\n",
    "        continue  # Skip this stock and do not save data\n",
    "\n",
    "    # Keep only the required columns (Open, High, Low, Close, Volume)\n",
    "    stock_data = stock_data[['Open', 'High', 'Low', 'Close', 'Volume']]\n",
    "    \n",
    "    # Save data as CSV\n",
    "    stock_data.to_csv(f\"{directory}/{ticker}.csv\")\n",
    "    print(f\"Data for {ticker} has been saved\")\n",
    "\n",
    "print(\"All eligible stock data has been successfully saved.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Set storage path\n",
    "directory = \"SP500_05_25\"\n",
    "\n",
    "# Process each CSV file\n",
    "for ticker in os.listdir(directory):\n",
    "    if ticker.endswith(\".csv\"):\n",
    "        file_path = os.path.join(directory, ticker)\n",
    "        \n",
    "        # Read the CSV file\n",
    "        df = pd.read_csv(file_path)\n",
    "\n",
    "        # Delete the second and third rows\n",
    "        df = df.drop([0, 1]).reset_index(drop=True)\n",
    "\n",
    "        # Remove rows containing NaN values\n",
    "        df = df.dropna()\n",
    "\n",
    "        # Rename the first column to 'Date'\n",
    "        df.columns.values[0] = 'Date'\n",
    "\n",
    "        # Save the modified file\n",
    "        df.to_csv(file_path, index=False)\n",
    "\n",
    "        print(f\"Processing complete: {ticker}\")\n",
    "\n",
    "print(\"ðŸŽ‰ All CSV files have been cleaned!\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xgboost",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
